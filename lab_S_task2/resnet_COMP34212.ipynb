{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COMP34212 Summative Lab Task2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "import torch.optim as optim\n",
    "\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from torchvision import datasets\n",
    "import torchvision.transforms as transforms\n",
    "import random\n",
    "import os\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu' # Check if GPU is available\n",
    "print('Using {} device'.format(device))\n",
    "\n",
    "folder_name = 'checkpoint' # Folder to save the model\n",
    "if not os.path.exists(folder_name):\n",
    "        os.makedirs(folder_name)\n",
    "\n",
    "# from torch.utils.tensorboard import SummaryWriter\n",
    "# writer = SummaryWriter(log_dir='./log') # Tensorboard writer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42\n",
    "def seed_torch(seed=1029):\n",
    "\trandom.seed(seed)\n",
    "\tos.environ['PYTHONHASHSEED'] = str(seed) # To make all the computations deterministic\n",
    "\tnp.random.seed(seed)\n",
    "\ttorch.manual_seed(seed)\n",
    "\ttorch.cuda.manual_seed(seed)\n",
    "\ttorch.cuda.manual_seed_all(seed) # if you are using multi-GPU.\n",
    "\ttorch.backends.cudnn.benchmark = False\n",
    "\ttorch.backends.cudnn.deterministic = True\n",
    "\n",
    "seed_torch(seed=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_fn(worker_id):\n",
    "    np.random.seed(int(seed)+worker_id)\n",
    "# trainloader = DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=num_workers, pin_memory=True, worker_init_fn=_init_fn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv3x3(in_planes, out_planes, stride=1, groups=1, dilation=1):\n",
    "    \"\"\"3x3 convolution with padding\"\"\"\n",
    "    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n",
    "                     padding=dilation, groups=groups, bias=False, dilation=dilation)\n",
    "\n",
    "# TODO: change variable names\n",
    "def conv1x1(in_planes, out_planes, stride=1):\n",
    "    \"\"\"1x1 convolution\"\"\"\n",
    "    return nn.Conv2d(in_planes, out_planes, kernel_size=1, stride=stride, bias=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicBlock(nn.Module):\n",
    "    \"\"\"\n",
    "    A basic block for ResNet18 and ResNet34\n",
    "\n",
    "    Args:\n",
    "    inplanes: int, number of input channels\n",
    "    planes: int, number of output channels\n",
    "    stride: int, stride of the first convolutional layer\n",
    "    downsample: nn.Module, downsample layer\n",
    "    groups: int, number of groups for the convolutional layers\n",
    "    base_width: int, base width of the convolutional layers\n",
    "    dilation: int, dilation rate of the convolutional layers\n",
    "    norm_layer: nn.Module, normalization layer\n",
    "\n",
    "    Returns:\n",
    "    out: tensor, output of the basic block\n",
    "    \"\"\"\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, inplanes, planes, stride=1, downsample=None, groups=1,\n",
    "                 base_width=64, dilation=1, norm_layer=None):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        if norm_layer is None:\n",
    "            norm_layer = nn.BatchNorm2d\n",
    "        if groups != 1 or base_width != 64:\n",
    "            raise ValueError('BasicBlock only supports groups=1 and base_width=64')\n",
    "        if dilation > 1:\n",
    "            raise NotImplementedError(\"Dilation > 1 not supported in BasicBlock\")\n",
    "        # Both self.conv1 and self.downsample layers downsample the input when stride != 1\n",
    "        self.conv1 = conv3x3(inplanes, planes, stride)\n",
    "        self.bn1 = norm_layer(planes)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv2 = conv3x3(planes, planes)\n",
    "        self.bn2 = norm_layer(planes)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "\n",
    "        out = self.relu(self.bn1(self.conv1(x)))\n",
    "\n",
    "        out = self.bn2(self.conv2(out))\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            identity = self.downsample(x)\n",
    "\n",
    "        out += identity\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Bottleneck(nn.Module):\n",
    "    \"\"\"\n",
    "    For deeper models, we use the \"bottleneck\" building block to reduce the number of parameters.\n",
    "    It is based on the following principle:\n",
    "    1. A 1x1 convolution reduces the dimensionality of the input to a bottleneck representation.\n",
    "    2. A 3x3 convolution is applied to the bottleneck representation.\n",
    "    3. A 1x1 convolution increases the dimensionality of the representation back to the original.\n",
    "    4. The output is added to the original input.\n",
    "    5. The result is passed through a ReLU activation function.\n",
    "\n",
    "    The bottleneck block is used in the ResNet-50, ResNet-101, and ResNet-152 architectures.\n",
    "    \"\"\"\n",
    "    # Bottleneck in torchvision places the stride for downsampling at 3x3 convolution(self.conv2)\n",
    "    # while original implementation places the stride at the first 1x1 convolution(self.conv1)\n",
    "    # according to \"Deep residual learning for image recognition\"https://arxiv.org/abs/1512.03385.\n",
    "    # This variant is also known as ResNet V1.5 and improves accuracy according to\n",
    "    # https://ngc.nvidia.com/catalog/model-scripts/nvidia:resnet_50_v1_5_for_pytorch.\n",
    "\n",
    "    expansion = 4\n",
    "\n",
    "    def __init__(self, inplanes, planes, stride=1, downsample=None, groups=1,\n",
    "                 base_width=64, dilation=1, norm_layer=None):\n",
    "        super(Bottleneck, self).__init__()\n",
    "        if norm_layer is None:\n",
    "            norm_layer = nn.BatchNorm2d\n",
    "        width = int(planes * (base_width / 64.)) * groups\n",
    "        # Both self.conv2 and self.downsample layers downsample the input when stride != 1\n",
    "        self.conv1 = conv1x1(inplanes, width)\n",
    "        self.bn1 = norm_layer(width)\n",
    "        self.conv2 = conv3x3(width, width, stride, groups, dilation)\n",
    "        self.bn2 = norm_layer(width)\n",
    "        self.conv3 = conv1x1(width, planes * self.expansion)\n",
    "        self.bn3 = norm_layer(planes * self.expansion)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv3(out)\n",
    "        out = self.bn3(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            identity = self.downsample(x)\n",
    "\n",
    "        out += identity\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet(nn.Module):\n",
    "    \"\"\"\n",
    "    The ResNet architecture is based on the following principles:\n",
    "    1. The input is passed through a 7x7 convolutional layer with stride 2.\n",
    "    2. The output is passed through a 3x3 max pooling layer with stride 2.\n",
    "    3. The output is passed through a series of residual blocks.\n",
    "    4. The output is passed through a global average pooling layer.\n",
    "    5. The output is passed through a fully connected layer with softmax activation.\n",
    "\n",
    "    The ResNet architecture is defined by the number of layers and the type of residual block used.\n",
    "    The ResNet-18 and ResNet-34 architectures use the \"basic block\" residual block.\n",
    "    The ResNet-50, ResNet-101, and ResNet-152 architectures use the \"bottleneck\" residual block.\n",
    "    \"\"\"\n",
    "    def __init__(self, block, layers, num_classes=1000, zero_init_residual=False,\n",
    "                 groups=1, width_per_group=64, replace_stride_with_dilation=None,\n",
    "                 norm_layer=None):\n",
    "        super(ResNet, self).__init__()\n",
    "        if norm_layer is None:\n",
    "            norm_layer = nn.BatchNorm2d\n",
    "        self._norm_layer = norm_layer\n",
    "\n",
    "        self.inplanes = 64\n",
    "        self.dilation = 1\n",
    "        if replace_stride_with_dilation is None:\n",
    "            # each element in the tuple indicates if we should replace\n",
    "            # the 2x2 stride with a dilated convolution instead\n",
    "            replace_stride_with_dilation = [False, False, False]\n",
    "        if len(replace_stride_with_dilation) != 3:\n",
    "            raise ValueError(\"replace_stride_with_dilation should be None \"\n",
    "                             \"or a 3-element tuple, got {}\".format(replace_stride_with_dilation))\n",
    "        self.groups = groups\n",
    "        self.base_width = width_per_group\n",
    "        self.conv1 = nn.Conv2d(3, self.inplanes, kernel_size=7, stride=2, padding=3,\n",
    "                               bias=False)\n",
    "        self.bn1 = norm_layer(self.inplanes)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        #self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)    # delete maxpool layer\n",
    "        self.layer1 = self._make_layer(block, 64, layers[0])\n",
    "        self.layer2 = self._make_layer(block, 128, layers[1], stride=2,\n",
    "                                       dilate=replace_stride_with_dilation[0])\n",
    "        self.layer3 = self._make_layer(block, 256, layers[2], stride=2,\n",
    "                                       dilate=replace_stride_with_dilation[1])\n",
    "        self.layer4 = self._make_layer(block, 512, layers[3], stride=2,\n",
    "                                       dilate=replace_stride_with_dilation[2])\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.fc = nn.Linear(512 * block.expansion, num_classes)\n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "            elif isinstance(m, (nn.BatchNorm2d, nn.GroupNorm)):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "\n",
    "        # Zero-initialize the last BN in each residual branch,\n",
    "        # so that the residual branch starts with zeros, and each residual block behaves like an identity.\n",
    "        # This improves the model by 0.2~0.3% according to https://arxiv.org/abs/1706.02677\n",
    "        if zero_init_residual:\n",
    "            for m in self.modules():\n",
    "                if isinstance(m, Bottleneck):\n",
    "                    nn.init.constant_(m.bn3.weight, 0)\n",
    "                elif isinstance(m, BasicBlock):\n",
    "                    nn.init.constant_(m.bn2.weight, 0)\n",
    "\n",
    "    def _make_layer(self, block, planes, blocks, stride=1, dilate=False):\n",
    "        \"\"\"\n",
    "        Create a layer of residual blocks\n",
    "\n",
    "        Args:\n",
    "        block: nn.Module, type of residual block: BasicBlock or Bottleneck\n",
    "        planes: int, number of output channels\n",
    "        blocks: int, number of blocks\n",
    "        \"\"\"\n",
    "        norm_layer = self._norm_layer\n",
    "        downsample = None\n",
    "        previous_dilation = self.dilation\n",
    "        if dilate:\n",
    "            self.dilation *= stride\n",
    "            stride = 1\n",
    "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
    "            downsample = nn.Sequential(\n",
    "                conv1x1(self.inplanes, planes * block.expansion, stride),\n",
    "                norm_layer(planes * block.expansion),\n",
    "            )\n",
    "\n",
    "        layers = []\n",
    "        layers.append(block(self.inplanes, planes, stride, downsample, self.groups,\n",
    "                            self.base_width, previous_dilation, norm_layer))\n",
    "        self.inplanes = planes * block.expansion\n",
    "        for _ in range(1, blocks):\n",
    "            layers.append(block(self.inplanes, planes, groups=self.groups,\n",
    "                                base_width=self.base_width, dilation=self.dilation,\n",
    "                                norm_layer=norm_layer))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def _forward_impl(self, x):\n",
    "        # See note [TorchScript super()]\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        #x = self.maxpool(x)\n",
    "\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "\n",
    "        x = self.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self._forward_impl(x)\n",
    "\n",
    "\n",
    "def _resnet(block, layers, **kwargs):\n",
    "    model = ResNet(block, layers, **kwargs)\n",
    "    return model\n",
    "\n",
    "\n",
    "def ResNet18(**kwargs):\n",
    "    return _resnet(BasicBlock, [2, 2, 2, 2],**kwargs)\n",
    "\n",
    "def ResNet34(**kwargs):\n",
    "    return _resnet(BasicBlock, [3, 4, 6, 3],**kwargs)\n",
    "\n",
    "def ResNet50(**kwargs):\n",
    "    return _resnet(Bottleneck, [3, 4, 6, 3],**kwargs)\n",
    "\n",
    "def ResNet101(**kwargs):\n",
    "    return _resnet(Bottleneck, [3, 4, 23, 3],**kwargs)\n",
    "\n",
    "def ResNet152(**kwargs):\n",
    "    return _resnet(Bottleneck, [3, 8, 36, 3],**kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Cutout(object):\n",
    "    \"\"\"\n",
    "    Randomly mask out one or more patches from an image.\n",
    "    Args:\n",
    "        n_holes (int): Number of patches to cut out of each image.\n",
    "        length (int): The length (in pixels) of each square patch.\n",
    "    \"\"\"\n",
    "    def __init__(self, n_holes, length):\n",
    "        self.n_holes = n_holes\n",
    "        self.length = length\n",
    "\n",
    "    def __call__(self, img):\n",
    "        h = img.size(1)\n",
    "        w = img.size(2)\n",
    "\n",
    "        mask = np.ones((h, w), np.float32)\n",
    "\n",
    "        for n in range(self.n_holes):\n",
    "        \t# (x,y) makes the center of the hole\n",
    "            y = np.random.randint(h)\n",
    "            x = np.random.randint(w)\n",
    "\n",
    "            y1 = np.clip(y - self.length // 2, 0, h)\n",
    "            y2 = np.clip(y + self.length // 2, 0, h)\n",
    "            x1 = np.clip(x - self.length // 2, 0, w)\n",
    "            x2 = np.clip(x + self.length // 2, 0, w)\n",
    "\n",
    "            mask[y1: y2, x1: x2] = 0.\n",
    "\n",
    "        mask = torch.from_numpy(mask)\n",
    "        mask = mask.expand_as(img)\n",
    "        img = img * mask\n",
    "\n",
    "        return img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fetch data for training/validation/test\n",
    "(Load CIFAR 10 and apply data augementation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_dataset(batch_size=16,valid_size=0.2,num_workers=0,pic_path='dataset'):\n",
    "    \"\"\"\n",
    "    batch_size: Number of loaded drawings per batch\n",
    "    valid_size: Percentage of training set to use as validation\n",
    "    num_workers: Number of subprocesses to use for data loading\n",
    "    pic_path: The path of the pictrues\n",
    "    \"\"\"\n",
    "    transform_train = transforms.Compose([\n",
    "        transforms.RandomCrop(32, padding=4),  # first, we perform a random crop of the image to 32x32 using padding of 4 pixels\n",
    "        transforms.RandomHorizontalFlip(),  # randomly flip the image horizontally, probability of 0.5\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406],std=[0.229, 0.224, 0.225]), # normalize the image based on the mean and standard deviation from the ImageNet dataset\n",
    "        Cutout(n_holes=1, length=16),\n",
    "    ])\n",
    "\n",
    "    transform_test = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406],std=[0.229, 0.224, 0.225]),\n",
    "    ])\n",
    "\n",
    "\n",
    "    # Define the data loaders\n",
    "    train_data = datasets.CIFAR10(pic_path, train=True,\n",
    "                                download=True, transform=transform_train)\n",
    "    valid_data = datasets.CIFAR10(pic_path, train=True,\n",
    "                                download=True, transform=transform_test)\n",
    "    test_data = datasets.CIFAR10(pic_path, train=False,\n",
    "                                download=True, transform=transform_test)\n",
    "        \n",
    "\n",
    "    # obtain training indices that will be used for validation\n",
    "    num_train = len(train_data)\n",
    "    indices = list(range(num_train))\n",
    "    # random indices\n",
    "    np.random.shuffle(indices)\n",
    "    # the ratio of split\n",
    "    split = int(np.floor(valid_size * num_train))\n",
    "    # divide data to radin_data and valid_data\n",
    "    train_idx, valid_idx = indices[split:], indices[:split]\n",
    "\n",
    "    # define samplers for obtaining training and validation batches\n",
    "    # samples elements randomly from a given list of indices, while not repeating elements\n",
    "    train_sampler = SubsetRandomSampler(train_idx)\n",
    "    valid_sampler = SubsetRandomSampler(valid_idx)\n",
    "\n",
    "    # prepare data loaders (combine dataset and sampler)\n",
    "    train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size,\n",
    "        sampler=train_sampler, num_workers=num_workers)\n",
    "    valid_loader = torch.utils.data.DataLoader(valid_data, batch_size=batch_size, \n",
    "        sampler=valid_sampler, num_workers=num_workers)\n",
    "    test_loader = torch.utils.data.DataLoader(test_data, batch_size=batch_size, \n",
    "        num_workers=num_workers)\n",
    "\n",
    "    return train_loader,valid_loader,test_loader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TRAINING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, train_loader): \n",
    "    model.train() # batchNorm or dropout layers will work in training mode\n",
    "    train_loss = 0.0\n",
    "    train_correct = 0\n",
    "    train_total = 0\n",
    "\n",
    "    for data, target in train_loader:\n",
    "        data = data.to(device)\n",
    "        target = target.to(device)\n",
    "        optimizer.zero_grad()   # clear the gradients of all optimized variables\n",
    "        # forward pass: compute predicted outputs by passing inputs to the model\n",
    "        output = model(data).to(device)  # output = model.forward(data).to(device)\n",
    "        # calculate the batch loss\n",
    "        loss = criterion(output, target)\n",
    "        # backward pass: compute gradient of the loss with respect to model parameters\n",
    "        loss.backward()\n",
    "        # perform a single optimization step (parameter update)\n",
    "        optimizer.step()\n",
    "        \n",
    "        # update training loss\n",
    "        train_loss += loss.item()*data.size(0)\n",
    "\n",
    "        _, pred = torch.max(output, 1)    \n",
    "        correct_tensor = pred.eq(target.data)\n",
    "        train_correct += torch.sum(correct_tensor).item()\n",
    "        train_total += data.size(0)\n",
    "\n",
    "    train_accuracy = train_correct / train_total\n",
    "    train_loss /= len(train_loader.sampler)\n",
    "    \n",
    "    return train_loss, train_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, criterion, valid_loader):\n",
    "    model.eval()\n",
    "    valid_loss = 0.0\n",
    "    \n",
    "    total_sample = 0\n",
    "    right_sample = 0\n",
    "    valid_accuracy = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data, target in valid_loader:\n",
    "            data = data.to(device)\n",
    "            target = target.to(device)\n",
    "            # forward pass: compute predicted outputs by passing inputs to the model\n",
    "            output = model(data).to(device)\n",
    "            # calculate the batch loss\n",
    "            loss = criterion(output, target)\n",
    "            \n",
    "            # update average validation loss \n",
    "            valid_loss += loss.item()*data.size(0)\n",
    "            # convert output probabilities to predicted class\n",
    "            _, pred = torch.max(output, 1)    \n",
    "            # compare predictions to true label\n",
    "            correct_tensor = pred.eq(target.data.view_as(pred))\n",
    "            # right_sample += torch.sum(correct_tensor).item()\n",
    "            # correct = np.squeeze(correct_tensor.to(device).numpy())\n",
    "            total_sample += data.size(0)\n",
    "            for i in correct_tensor:\n",
    "                if i:\n",
    "                    right_sample += 1\n",
    "\n",
    "    valid_accuracy = right_sample / total_sample\n",
    "    valid_loss /= len(valid_loader.sampler)\n",
    "\n",
    "    return valid_loss, valid_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_validate(model, optimizer, criterion, trainloader, valloader, num_epochs, save_path = 'checkpoint/resnet18_cifar10.pt'):\n",
    "    # model.to(device)\n",
    "    valid_loss_min = np.Inf # track change in validation loss\n",
    "    counter = 0\n",
    "    early_stop_threshold = 50   # early stopping patience\n",
    "\n",
    "    train_loss = 0.0\n",
    "    train_accuracy=0.0\n",
    "\n",
    "    valid_loss = 0.0\n",
    "    val_accuracy=0.0\n",
    "        \n",
    "    for epoch in tqdm(range(50, num_epochs+1)):\n",
    "\n",
    "        # Dynamic learning rate\n",
    "        if counter/10 ==1:\n",
    "            counter = 0\n",
    "            lr = lr*0.5\n",
    "        \n",
    "        train_loss, train_accuracy = train_model(model,criterion,optimizer,trainloader)\n",
    "        valid_loss, valid_accuracy = evaluate_model(model,criterion,valloader)\n",
    "        \n",
    "        print(\"Train Accuracy:\",100.*train_accuracy,\"%  \\n\",\"Evaluation Accuracy:\",100.*valid_accuracy,\"%\")\n",
    "        \n",
    "        # train_loss = train_loss/len(train_loader.sampler)\n",
    "        # valid_loss = valid_loss/len(valid_loader.sampler)\n",
    "        print('Epoch: {} \\tTraining Loss: {:.6f} \\tValidation Loss: {:.6f}'.format(\n",
    "        epoch, train_loss, valid_loss))\n",
    "        # writer.add_scalar('Train Loss', train_loss, valid_loss, epoch)\n",
    "\n",
    "        # if the validation loss has decreased, save the model\n",
    "        if valid_loss <= valid_loss_min:\n",
    "            print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(valid_loss_min,valid_loss))\n",
    "            torch.save(model.state_dict(), save_path)\n",
    "            valid_loss_min = valid_loss\n",
    "            counter = 0\n",
    "        else:\n",
    "            counter += 1\n",
    "            # Early stopping\n",
    "            if counter >= early_stop_threshold:\n",
    "                print(\"Early stopping\")\n",
    "                break\n",
    "\n",
    "    return train_loss, train_accuracy, valid_loss, val_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_workers = 8 # number of subprocesses to use for data loading\n",
    "batch_size = 128 # how many samples per batch to load\n",
    "valid_size = 0.2    # percentage of training set to use as validation\n",
    "\n",
    "batch_size = 128\n",
    "train_loader,valid_loader,test_loader = read_dataset(batch_size=batch_size,pic_path='dataset')\n",
    "n_class = 10\n",
    "\n",
    "\"\"\"\n",
    "ResNet18网络的7x7降采样卷积和池化操作容易丢失一部分信息,\n",
    "所以在实验中我们将7x7的降采样层和最大池化层去掉,替换为一个3x3的降采样卷积,\n",
    "同时减小该卷积层的步长和填充大小\n",
    "\"\"\"\n",
    "model = ResNet18()\n",
    "model.conv1 = nn.Conv2d(in_channels=3, out_channels=64, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "model.fc = torch.nn.Linear(512, n_class) # modify the last layer for ResNet18\n",
    "# model.fc = torch.nn.Linear(2048, n_class) # modify the last layer for ResNet50\n",
    "\n",
    "# Load the model parameters from disk\n",
    "checkpoint_path = 'checkpoint/resnet18_cifar10.pt'\n",
    "if os.path.exists(checkpoint_path):\n",
    "    model_state_dict = torch.load(checkpoint_path)\n",
    "    model.load_state_dict(model_state_dict)\n",
    "    print(\"Loaded model parameters from disk.\")\n",
    "\n",
    "model = model.to(device)\n",
    "criterion = nn.CrossEntropyLoss().to(device)    # Use cross entropy loss function\n",
    "n_epochs = 250\n",
    "lr = 0.1\n",
    "optimizer_SGD = optim.SGD(model.parameters(), lr=lr, momentum=0.9, weight_decay=5e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_and_validate(model, optimizer_SGD, criterion, train_loader, valid_loader, num_epochs=n_epochs, save_path = 'checkpoint/resnet18_cifar10.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TEST\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_class = 10\n",
    "batch_size = 100\n",
    "train_loader,valid_loader,test_loader = read_dataset(batch_size=batch_size,pic_path='dataset')\n",
    "model = ResNet18()\n",
    "model.conv1 = nn.Conv2d(in_channels=3, out_channels=64, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "model.fc = torch.nn.Linear(512, n_class) # modify the last layer for ResNet18\n",
    "# model.fc = torch.nn.Linear(2048, n_class) # modify the last layer for ResNet50\n",
    "\n",
    "# Load the model parameters from disk\n",
    "model.load_state_dict(torch.load('checkpoint/resnet18_cifar10.pt'))\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(model, test_loader):\n",
    "    model.eval()\n",
    "    total_sample = 0\n",
    "    right_sample = 0\n",
    "    for data, target in test_loader:\n",
    "        data = data.to(device)\n",
    "        target = target.to(device)\n",
    "        # forward pass: compute predicted outputs by passing inputs to the model\n",
    "        output = model(data).to(device)\n",
    "        # convert output probabilities to predicted class\n",
    "        _, pred = torch.max(output, 1)    \n",
    "        # compare predictions to true label\n",
    "        correct_tensor = pred.eq(target.data.view_as(pred))\n",
    "        # correct = np.squeeze(correct_tensor.to(device).numpy())\n",
    "        total_sample += batch_size\n",
    "        for i in correct_tensor:\n",
    "            if i:\n",
    "                right_sample += 1\n",
    "\n",
    "    print(\"Accuracy:\",100*right_sample/total_sample,\"%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
