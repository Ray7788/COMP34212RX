{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COMP34212 Summative Lab\n",
    "## Resnet Architecture on CIFAR-10 Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "rj_tptb2W8Lg"
   },
   "outputs": [],
   "source": [
    "#import the necessary libraries\n",
    "from math import sqrt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.nn.init as init\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "from torchsummary import summary\n",
    "#The following imports are used for Bayesian Optimization\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from skopt import gp_minimize\n",
    "from skopt.space import Real, Integer\n",
    "from skopt.utils import use_named_args\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import Matern\n",
    "from skopt import gp_minimize\n",
    "from skopt.space import Real\n",
    "from skopt.utils import use_named_args\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fetch Data (Load CIFAR 10 and apply data augementation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "G--Pd6U5eU7U"
   },
   "outputs": [],
   "source": [
    "def fetch_data():\n",
    "    # Load the CIFAR-10 dataset and apply data augmentation\n",
    "    transform_train = transforms.Compose([\n",
    "        transforms.RandomCrop(32, padding=4),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.4914, 0.4822, 0.4465], std=[0.2023, 0.1994, 0.2010])\n",
    "    ])\n",
    "\n",
    "    transform_test = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.4914, 0.4822, 0.4465], std=[0.2023, 0.1994, 0.2010])\n",
    "    ])\n",
    "\n",
    "    # Load the CIFAR-10 dataset\n",
    "    train_set = datasets.CIFAR10(root='./dataset', train=True, download=True, transform=transform_train)\n",
    "    test_set = datasets.CIFAR10(root='./dataset', train=False, download=True, transform=transform_test)\n",
    "\n",
    "    # Split train set into train and validation sets\n",
    "    train_size = int(0.8 * len(train_set))\n",
    "    val_size = len(train_set) - train_size\n",
    "    train_dataset, val_dataset = torch.utils.data.random_split(train_set, [train_size, val_size])\n",
    "\n",
    "    # Create data loaders for train, validation, and test sets\n",
    "    train_data_loader = torch.utils.data.DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "    val_data_loader = torch.utils.data.DataLoader(val_dataset, batch_size=32, shuffle=True)\n",
    "    test_data_loader = torch.utils.data.DataLoader(test_set, batch_size=32, shuffle=False)\n",
    "\n",
    "    return train_data_loader, val_data_loader, test_data_loader\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DEFINE RESNET Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "gcG2AJ2jdhQ2"
   },
   "outputs": [],
   "source": [
    "# Define the ResNet architecture\n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self, block, num_blocks, num_classes=10):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.in_planes = 64\n",
    "\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=3,\n",
    "                               stride=1, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.layer1 = self._make_layer(block, 64, num_blocks[0], stride=1)\n",
    "        self.layer2 = self._make_layer(block, 128, num_blocks[1], stride=2)\n",
    "        self.layer3 = self._make_layer(block, 256, num_blocks[2], stride=2)\n",
    "        self.layer4 = self._make_layer(block, 512, num_blocks[3], stride=2)\n",
    "        self.linear1 = nn.Linear(512*block.expansion, num_classes)\n",
    "\n",
    "    def _make_layer(self, block, planes, num_blocks, stride, kernel_size=3):\n",
    "        strides = [stride] + [1]*(num_blocks-1)\n",
    "        layers = []\n",
    "        for stride in strides:\n",
    "            layers.append(block(self.in_planes, planes, stride, kernel_size))\n",
    "            self.in_planes = planes * block.expansion\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.layer4(out)\n",
    "        out = F.avg_pool2d(out, 4)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.linear1(out)\n",
    "        return out\n",
    "\n",
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, in_planes, planes, stride=1, kernel_size=3):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(\n",
    "            in_planes, planes, kernel_size=kernel_size, stride=stride, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=kernel_size,\n",
    "                               stride=1, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_planes != self.expansion*planes:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_planes, self.expansion*planes,\n",
    "                          kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(self.expansion*planes),\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.bn2(self.conv2(out))\n",
    "        out += self.shortcut(x)\n",
    "        out = F.relu(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DEFINE UTILITY FUNCTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "X6ITldzxC9Ix"
   },
   "outputs": [],
   "source": [
    "def train(model, optimizer, criterion, trainloader):\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    train_correct = 0\n",
    "    train_total = 0\n",
    "\n",
    "    for batch_idx, (inputs, targets) in enumerate(trainloader):\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        train_total += targets.size(0)\n",
    "        train_correct += predicted.eq(targets).sum().item()\n",
    "\n",
    "    train_accuracy = 100. * train_correct / train_total\n",
    "    train_loss /= len(trainloader)\n",
    "    print('Training - Loss: {:.4f}, Accuracy: {:.4f}%'.format(train_loss, train_accuracy))\n",
    "\n",
    "    return train_loss, train_accuracy\n",
    "\n",
    "\n",
    "def evaluate(model, criterion, testloader):\n",
    "    model.eval()\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    test_loss = 0.0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in testloader:\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            test_loss += loss.item() * labels.size(0)\n",
    "\n",
    "    test_accuracy = 100 * correct / total\n",
    "    test_loss /= len(testloader.dataset)\n",
    "    \n",
    "    print('Validation - Loss: {:.4f}, Accuracy: {:.4f}%'.format(test_loss , test_accuracy))\n",
    "   \n",
    "    \n",
    "    # scheduler.step(test_accuracy)\n",
    "\n",
    "    return test_loss, test_accuracy\n",
    "\n",
    "\n",
    "def train_and_validate(model, optimizer, criterion, trainloader, valloader, num_epochs):\n",
    "    model.to(device)\n",
    "\n",
    "    train_loss = 0.0\n",
    "    train_accuracy=0.0\n",
    "    \n",
    "    val_total = 0\n",
    "    val_accuracy=0.0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch+1, num_epochs))\n",
    "        print('-' * 10)\n",
    "        \n",
    "        train_loss,train_accuracy = train(model,optimizer,criterion,trainloader)\n",
    "        val_loss,val_accuracy = evaluate(model,criterion,valloader)\n",
    "        \n",
    "       \n",
    "\n",
    "    return train_loss, train_accuracy, val_loss, val_accuracy\n",
    "\n",
    "def test(model,criterion,testloader):\n",
    "    \n",
    "    model.eval()\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    test_loss = 0.0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in testloader:\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            test_loss += loss.item() * labels.size(0)\n",
    "\n",
    "    test_accuracy = 100 * correct / total\n",
    "    test_loss /= len(testloader.dataset)\n",
    "    \n",
    "    print('Testing - Loss: {:.4f}, Accuracy: {:.4f}%'.format(test_loss , test_accuracy))\n",
    "    \n",
    "    \n",
    "\n",
    "    return test_loss, test_accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "O9x8jsZUBTMb",
    "outputId": "d68f1de5-2fde-42ab-8bf2-839c15d5e609"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# Load the CIFAR-10 dataset \n",
    "trainloader,valloader,testloader = fetch_data()\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Testing hyperparameters: lr=0.0036063486397284665, beta1=0.8589949079743348, beta2=0.8712931102428585, weight_decay=0.0003481410351917474\n",
      "Epoch 1/20\n",
      "----------\n",
      "Training - Loss: 1.7548, Accuracy: 33.9575%\n",
      "Validation - Loss: 1.6401, Accuracy: 39.6600%\n",
      "Epoch 2/20\n",
      "----------\n",
      "Training - Loss: 1.3544, Accuracy: 50.4150%\n",
      "Validation - Loss: 1.2186, Accuracy: 55.1100%\n",
      "Epoch 3/20\n",
      "----------\n",
      "Training - Loss: 1.1552, Accuracy: 58.6425%\n",
      "Validation - Loss: 1.1627, Accuracy: 58.5900%\n",
      "Epoch 4/20\n",
      "----------\n",
      "Training - Loss: 1.0485, Accuracy: 62.8150%\n",
      "Validation - Loss: 1.2691, Accuracy: 56.1500%\n",
      "Epoch 5/20\n",
      "----------\n",
      "Training - Loss: 0.9862, Accuracy: 65.0125%\n",
      "Validation - Loss: 1.1857, Accuracy: 58.5000%\n",
      "Epoch 6/20\n",
      "----------\n",
      "Training - Loss: 0.9325, Accuracy: 67.0675%\n",
      "Validation - Loss: 0.9947, Accuracy: 64.7800%\n",
      "Epoch 7/20\n",
      "----------\n",
      "Training - Loss: 0.8957, Accuracy: 68.4350%\n",
      "Validation - Loss: 0.8782, Accuracy: 69.3300%\n",
      "Epoch 8/20\n",
      "----------\n",
      "Training - Loss: 0.8576, Accuracy: 70.1525%\n",
      "Validation - Loss: 0.8409, Accuracy: 70.6900%\n",
      "Epoch 9/20\n",
      "----------\n",
      "Training - Loss: 0.8274, Accuracy: 71.1550%\n",
      "Validation - Loss: 0.8033, Accuracy: 71.0100%\n",
      "Epoch 10/20\n",
      "----------\n",
      "Training - Loss: 0.7995, Accuracy: 72.2450%\n",
      "Validation - Loss: 0.7949, Accuracy: 72.2500%\n",
      "Epoch 11/20\n",
      "----------\n",
      "Training - Loss: 0.7741, Accuracy: 73.0725%\n",
      "Validation - Loss: 0.8167, Accuracy: 71.0500%\n",
      "Epoch 12/20\n",
      "----------\n",
      "Training - Loss: 0.7638, Accuracy: 73.4975%\n",
      "Validation - Loss: 0.7888, Accuracy: 72.5800%\n",
      "Epoch 13/20\n",
      "----------\n",
      "Training - Loss: 0.7497, Accuracy: 74.0000%\n",
      "Validation - Loss: 0.7901, Accuracy: 72.0000%\n",
      "Epoch 14/20\n",
      "----------\n",
      "Training - Loss: 0.7344, Accuracy: 74.6400%\n",
      "Validation - Loss: 0.6971, Accuracy: 75.5800%\n",
      "Epoch 15/20\n",
      "----------\n",
      "Training - Loss: 0.7303, Accuracy: 74.6325%\n",
      "Validation - Loss: 0.7052, Accuracy: 75.3600%\n",
      "Epoch 16/20\n",
      "----------\n",
      "Training - Loss: 0.7301, Accuracy: 74.5875%\n",
      "Validation - Loss: 0.7874, Accuracy: 72.9300%\n",
      "Epoch 17/20\n",
      "----------\n",
      "Training - Loss: 0.7209, Accuracy: 75.3725%\n",
      "Validation - Loss: 0.7408, Accuracy: 74.4400%\n",
      "Epoch 18/20\n",
      "----------\n",
      "Training - Loss: 0.7175, Accuracy: 75.2350%\n",
      "Validation - Loss: 0.7684, Accuracy: 73.9000%\n",
      "Epoch 19/20\n",
      "----------\n",
      "Training - Loss: 0.7135, Accuracy: 75.1550%\n",
      "Validation - Loss: 0.8382, Accuracy: 70.5400%\n",
      "Epoch 20/20\n",
      "----------\n",
      "Training - Loss: 0.7073, Accuracy: 75.7175%\n",
      "Validation - Loss: 0.8950, Accuracy: 69.4300%\n",
      "\n",
      " Testing hyperparameters: lr=0.0055129262250874335, beta1=0.4455591548561373, beta2=0.3674836112834806, weight_decay=1.4795816345422864e-06\n",
      "Epoch 1/20\n",
      "----------\n",
      "Training - Loss: 1.7065, Accuracy: 36.4200%\n",
      "Validation - Loss: 1.3609, Accuracy: 50.3500%\n",
      "Epoch 2/20\n",
      "----------\n",
      "Training - Loss: 1.2568, Accuracy: 54.4875%\n",
      "Validation - Loss: 1.1647, Accuracy: 59.0700%\n",
      "Epoch 3/20\n",
      "----------\n",
      "Training - Loss: 1.0432, Accuracy: 63.2500%\n",
      "Validation - Loss: 1.1082, Accuracy: 62.0400%\n",
      "Epoch 4/20\n",
      "----------\n",
      "Training - Loss: 0.9233, Accuracy: 67.8225%\n",
      "Validation - Loss: 0.8717, Accuracy: 69.2800%\n",
      "Epoch 5/20\n",
      "----------\n",
      "Training - Loss: 0.8212, Accuracy: 71.6050%\n",
      "Validation - Loss: 0.7791, Accuracy: 73.3800%\n",
      "Epoch 6/20\n",
      "----------\n",
      "Training - Loss: 0.7461, Accuracy: 74.1575%\n",
      "Validation - Loss: 0.7081, Accuracy: 76.6300%\n",
      "Epoch 7/20\n",
      "----------\n",
      "Training - Loss: 0.6866, Accuracy: 76.5125%\n",
      "Validation - Loss: 0.6751, Accuracy: 76.9400%\n",
      "Epoch 8/20\n",
      "----------\n",
      "Training - Loss: 0.6489, Accuracy: 77.9825%\n",
      "Validation - Loss: 0.6011, Accuracy: 79.0300%\n",
      "Epoch 9/20\n",
      "----------\n",
      "Training - Loss: 0.6170, Accuracy: 79.0675%\n",
      "Validation - Loss: 0.6911, Accuracy: 77.0800%\n",
      "Epoch 10/20\n",
      "----------\n",
      "Training - Loss: 0.5906, Accuracy: 80.0275%\n",
      "Validation - Loss: 0.6594, Accuracy: 77.5900%\n",
      "Epoch 11/20\n",
      "----------\n",
      "Training - Loss: 0.5676, Accuracy: 80.7950%\n",
      "Validation - Loss: 0.6087, Accuracy: 79.9700%\n",
      "Epoch 12/20\n",
      "----------\n",
      "Training - Loss: 0.5540, Accuracy: 81.5700%\n",
      "Validation - Loss: 0.5624, Accuracy: 81.1400%\n",
      "Epoch 13/20\n",
      "----------\n",
      "Training - Loss: 0.5377, Accuracy: 82.2675%\n",
      "Validation - Loss: 0.5827, Accuracy: 80.4500%\n",
      "Epoch 14/20\n",
      "----------\n",
      "Training - Loss: 0.5220, Accuracy: 82.5325%\n",
      "Validation - Loss: 0.5797, Accuracy: 81.1300%\n",
      "Epoch 15/20\n",
      "----------\n",
      "Training - Loss: 0.5105, Accuracy: 83.1925%\n",
      "Validation - Loss: 0.5652, Accuracy: 81.5700%\n",
      "Epoch 16/20\n",
      "----------\n",
      "Training - Loss: 0.4988, Accuracy: 83.4825%\n",
      "Validation - Loss: 0.5198, Accuracy: 82.1800%\n",
      "Epoch 17/20\n",
      "----------\n",
      "Training - Loss: 0.4845, Accuracy: 84.1225%\n",
      "Validation - Loss: 0.6020, Accuracy: 82.0100%\n",
      "Epoch 18/20\n",
      "----------\n",
      "Training - Loss: 0.4793, Accuracy: 84.4050%\n",
      "Validation - Loss: 0.5260, Accuracy: 82.7000%\n",
      "Epoch 19/20\n",
      "----------\n",
      "Training - Loss: 0.4676, Accuracy: 84.5825%\n",
      "Validation - Loss: 0.6185, Accuracy: 81.3500%\n",
      "Epoch 20/20\n",
      "----------\n",
      "Training - Loss: 0.4601, Accuracy: 84.9500%\n",
      "Validation - Loss: 0.6082, Accuracy: 82.4800%\n",
      "\n",
      " Testing hyperparameters: lr=4.324518581155819e-05, beta1=0.5294209404718937, beta2=0.8301396871691685, weight_decay=2.753794429736146e-05\n",
      "Epoch 1/20\n",
      "----------\n",
      "Training - Loss: 1.5127, Accuracy: 44.8700%\n",
      "Validation - Loss: 1.2570, Accuracy: 54.2400%\n",
      "Epoch 2/20\n",
      "----------\n",
      "Training - Loss: 1.1574, Accuracy: 58.7075%\n",
      "Validation - Loss: 1.0611, Accuracy: 61.9700%\n",
      "Epoch 3/20\n",
      "----------\n",
      "Training - Loss: 0.9782, Accuracy: 65.2950%\n",
      "Validation - Loss: 0.9100, Accuracy: 68.3600%\n",
      "Epoch 4/20\n",
      "----------\n",
      "Training - Loss: 0.8607, Accuracy: 70.1050%\n",
      "Validation - Loss: 0.8406, Accuracy: 70.2700%\n",
      "Epoch 5/20\n",
      "----------\n",
      "Training - Loss: 0.7741, Accuracy: 72.8900%\n",
      "Validation - Loss: 0.7716, Accuracy: 73.0700%\n",
      "Epoch 6/20\n",
      "----------\n",
      "Training - Loss: 0.7054, Accuracy: 75.5000%\n",
      "Validation - Loss: 0.7197, Accuracy: 74.4900%\n",
      "Epoch 7/20\n",
      "----------\n",
      "Training - Loss: 0.6540, Accuracy: 77.3850%\n",
      "Validation - Loss: 0.6913, Accuracy: 75.9800%\n",
      "Epoch 8/20\n",
      "----------\n",
      "Training - Loss: 0.6134, Accuracy: 78.7225%\n",
      "Validation - Loss: 0.6770, Accuracy: 76.2100%\n",
      "Epoch 9/20\n",
      "----------\n",
      "Training - Loss: 0.5767, Accuracy: 80.1800%\n",
      "Validation - Loss: 0.6348, Accuracy: 78.1100%\n",
      "Epoch 10/20\n",
      "----------\n",
      "Training - Loss: 0.5429, Accuracy: 81.3625%\n",
      "Validation - Loss: 0.6008, Accuracy: 78.9500%\n",
      "Epoch 11/20\n",
      "----------\n",
      "Training - Loss: 0.5167, Accuracy: 82.1300%\n",
      "Validation - Loss: 0.5653, Accuracy: 80.2700%\n",
      "Epoch 12/20\n",
      "----------\n",
      "Training - Loss: 0.4910, Accuracy: 83.1400%\n",
      "Validation - Loss: 0.5291, Accuracy: 81.5300%\n",
      "Epoch 13/20\n",
      "----------\n",
      "Training - Loss: 0.4710, Accuracy: 83.6250%\n",
      "Validation - Loss: 0.5631, Accuracy: 80.6900%\n",
      "Epoch 14/20\n",
      "----------\n",
      "Training - Loss: 0.4430, Accuracy: 84.5900%\n",
      "Validation - Loss: 0.5244, Accuracy: 82.1400%\n",
      "Epoch 15/20\n",
      "----------\n",
      "Training - Loss: 0.4248, Accuracy: 85.2650%\n",
      "Validation - Loss: 0.5193, Accuracy: 82.5500%\n",
      "Epoch 16/20\n",
      "----------\n",
      "Training - Loss: 0.4127, Accuracy: 85.9275%\n",
      "Validation - Loss: 0.5575, Accuracy: 81.4800%\n",
      "Epoch 17/20\n",
      "----------\n",
      "Training - Loss: 0.3962, Accuracy: 86.4125%\n",
      "Validation - Loss: 0.5092, Accuracy: 82.6000%\n",
      "Epoch 18/20\n",
      "----------\n",
      "Training - Loss: 0.3751, Accuracy: 87.0875%\n",
      "Validation - Loss: 0.4779, Accuracy: 83.8200%\n",
      "Epoch 19/20\n",
      "----------\n",
      "Training - Loss: 0.3668, Accuracy: 87.2925%\n",
      "Validation - Loss: 0.4995, Accuracy: 82.9300%\n",
      "Epoch 20/20\n",
      "----------\n",
      "Training - Loss: 0.3480, Accuracy: 87.9900%\n",
      "Validation - Loss: 0.4772, Accuracy: 84.0200%\n",
      "\n",
      " Testing hyperparameters: lr=0.00022735723377092203, beta1=0.8516348084201026, beta2=0.4033191482151244, weight_decay=8.800667561385513e-05\n",
      "Epoch 1/20\n",
      "----------\n",
      "Training - Loss: 1.3759, Accuracy: 49.8200%\n",
      "Validation - Loss: 1.0835, Accuracy: 61.5000%\n",
      "Epoch 2/20\n",
      "----------\n",
      "Training - Loss: 0.9502, Accuracy: 66.0650%\n",
      "Validation - Loss: 0.9434, Accuracy: 66.8900%\n",
      "Epoch 3/20\n",
      "----------\n",
      "Training - Loss: 0.7765, Accuracy: 73.0200%\n",
      "Validation - Loss: 0.7893, Accuracy: 72.8200%\n",
      "Epoch 4/20\n",
      "----------\n",
      "Training - Loss: 0.6755, Accuracy: 76.6000%\n",
      "Validation - Loss: 0.6186, Accuracy: 78.9700%\n",
      "Epoch 5/20\n",
      "----------\n",
      "Training - Loss: 0.6026, Accuracy: 79.2125%\n",
      "Validation - Loss: 0.6117, Accuracy: 78.7600%\n",
      "Epoch 6/20\n",
      "----------\n",
      "Training - Loss: 0.5516, Accuracy: 81.0075%\n",
      "Validation - Loss: 0.5820, Accuracy: 79.7800%\n",
      "Epoch 7/20\n",
      "----------\n",
      "Training - Loss: 0.5074, Accuracy: 82.4025%\n",
      "Validation - Loss: 0.5040, Accuracy: 83.0000%\n",
      "Epoch 8/20\n",
      "----------\n",
      "Training - Loss: 0.4685, Accuracy: 83.9700%\n",
      "Validation - Loss: 0.5239, Accuracy: 82.2800%\n",
      "Epoch 9/20\n",
      "----------\n",
      "Training - Loss: 0.4453, Accuracy: 84.7075%\n",
      "Validation - Loss: 0.4519, Accuracy: 84.5200%\n",
      "Epoch 10/20\n",
      "----------\n",
      "Training - Loss: 0.4161, Accuracy: 85.7000%\n",
      "Validation - Loss: 0.5271, Accuracy: 81.7100%\n",
      "Epoch 11/20\n",
      "----------\n",
      "Training - Loss: 0.3956, Accuracy: 86.4200%\n",
      "Validation - Loss: 0.4428, Accuracy: 84.7300%\n",
      "Epoch 12/20\n",
      "----------\n",
      "Training - Loss: 0.3785, Accuracy: 87.0500%\n",
      "Validation - Loss: 0.4272, Accuracy: 85.2800%\n",
      "Epoch 13/20\n",
      "----------\n",
      "Training - Loss: 0.3556, Accuracy: 87.7125%\n",
      "Validation - Loss: 0.4151, Accuracy: 85.8800%\n",
      "Epoch 14/20\n",
      "----------\n",
      "Training - Loss: 0.3463, Accuracy: 88.2450%\n",
      "Validation - Loss: 0.4400, Accuracy: 84.9400%\n",
      "Epoch 15/20\n",
      "----------\n",
      "Training - Loss: 0.3242, Accuracy: 88.7575%\n",
      "Validation - Loss: 0.4186, Accuracy: 85.8200%\n",
      "Epoch 16/20\n",
      "----------\n",
      "Training - Loss: 0.3143, Accuracy: 89.0875%\n",
      "Validation - Loss: 0.3999, Accuracy: 86.5300%\n",
      "Epoch 17/20\n",
      "----------\n",
      "Training - Loss: 0.2999, Accuracy: 89.6025%\n",
      "Validation - Loss: 0.4131, Accuracy: 86.0300%\n",
      "Epoch 18/20\n",
      "----------\n",
      "Training - Loss: 0.2870, Accuracy: 90.0600%\n",
      "Validation - Loss: 0.3733, Accuracy: 87.4800%\n",
      "Epoch 19/20\n",
      "----------\n",
      "Training - Loss: 0.2782, Accuracy: 90.3550%\n",
      "Validation - Loss: 0.4199, Accuracy: 86.1200%\n",
      "Epoch 20/20\n",
      "----------\n",
      "Training - Loss: 0.2661, Accuracy: 90.6525%\n",
      "Validation - Loss: 0.4260, Accuracy: 86.0400%\n",
      "\n",
      " Testing hyperparameters: lr=0.00016197546636104998, beta1=0.9604824878987889, beta2=0.22617535159096802, weight_decay=0.0004076259041096254\n",
      "Epoch 1/20\n",
      "----------\n",
      "Training - Loss: 1.5127, Accuracy: 44.3850%\n",
      "Validation - Loss: 1.1504, Accuracy: 58.5900%\n",
      "Epoch 2/20\n",
      "----------\n",
      "Training - Loss: 1.0635, Accuracy: 62.2275%\n",
      "Validation - Loss: 0.9510, Accuracy: 66.3200%\n",
      "Epoch 3/20\n",
      "----------\n",
      "Training - Loss: 0.8742, Accuracy: 69.1250%\n",
      "Validation - Loss: 0.8126, Accuracy: 71.2900%\n",
      "Epoch 4/20\n",
      "----------\n",
      "Training - Loss: 0.7444, Accuracy: 73.9325%\n",
      "Validation - Loss: 0.6725, Accuracy: 76.8600%\n",
      "Epoch 5/20\n",
      "----------\n",
      "Training - Loss: 0.6686, Accuracy: 76.8325%\n",
      "Validation - Loss: 0.6837, Accuracy: 75.3700%\n",
      "Epoch 6/20\n",
      "----------\n",
      "Training - Loss: 0.6088, Accuracy: 78.9325%\n",
      "Validation - Loss: 0.5918, Accuracy: 78.7800%\n",
      "Epoch 7/20\n",
      "----------\n",
      "Training - Loss: 0.5633, Accuracy: 80.7425%\n",
      "Validation - Loss: 0.5766, Accuracy: 80.1300%\n",
      "Epoch 8/20\n",
      "----------\n",
      "Training - Loss: 0.5220, Accuracy: 82.1175%\n",
      "Validation - Loss: 0.5915, Accuracy: 80.1100%\n",
      "Epoch 9/20\n",
      "----------\n",
      "Training - Loss: 0.4983, Accuracy: 82.9475%\n",
      "Validation - Loss: 0.5313, Accuracy: 81.3500%\n",
      "Epoch 10/20\n",
      "----------\n",
      "Training - Loss: 0.4644, Accuracy: 84.1000%\n",
      "Validation - Loss: 0.4795, Accuracy: 83.5100%\n",
      "Epoch 11/20\n",
      "----------\n",
      "Training - Loss: 0.4404, Accuracy: 84.9325%\n",
      "Validation - Loss: 0.4557, Accuracy: 84.5500%\n",
      "Epoch 12/20\n",
      "----------\n",
      "Training - Loss: 0.4170, Accuracy: 85.6225%\n",
      "Validation - Loss: 0.4726, Accuracy: 83.5300%\n",
      "Epoch 13/20\n",
      "----------\n",
      "Training - Loss: 0.4029, Accuracy: 86.1650%\n",
      "Validation - Loss: 0.4349, Accuracy: 84.9500%\n",
      "Epoch 14/20\n",
      "----------\n",
      "Training - Loss: 0.3885, Accuracy: 86.4600%\n",
      "Validation - Loss: 0.4293, Accuracy: 85.3400%\n",
      "Epoch 15/20\n",
      "----------\n",
      "Training - Loss: 0.3698, Accuracy: 87.2800%\n",
      "Validation - Loss: 0.4353, Accuracy: 85.3200%\n",
      "Epoch 16/20\n",
      "----------\n",
      "Training - Loss: 0.3543, Accuracy: 87.8950%\n",
      "Validation - Loss: 0.3790, Accuracy: 87.0400%\n",
      "Epoch 17/20\n",
      "----------\n",
      "Training - Loss: 0.3445, Accuracy: 88.2450%\n",
      "Validation - Loss: 0.4071, Accuracy: 85.7600%\n",
      "Epoch 18/20\n",
      "----------\n",
      "Training - Loss: 0.3361, Accuracy: 88.4425%\n",
      "Validation - Loss: 0.3577, Accuracy: 88.1500%\n",
      "Epoch 19/20\n",
      "----------\n",
      "Training - Loss: 0.3174, Accuracy: 89.1900%\n",
      "Validation - Loss: 0.3817, Accuracy: 87.0200%\n",
      "Epoch 20/20\n",
      "----------\n",
      "Training - Loss: 0.3107, Accuracy: 89.4075%\n",
      "Validation - Loss: 0.3846, Accuracy: 86.8900%\n",
      "\n",
      " Testing hyperparameters: lr=0.0006944616560615827, beta1=0.8200187660297004, beta2=0.5679092541165333, weight_decay=0.00010880242882938465\n",
      "Epoch 1/20\n",
      "----------\n",
      "Training - Loss: 1.4162, Accuracy: 48.5875%\n",
      "Validation - Loss: 1.0724, Accuracy: 61.0600%\n",
      "Epoch 2/20\n",
      "----------\n",
      "Training - Loss: 1.0170, Accuracy: 63.6300%\n",
      "Validation - Loss: 0.9666, Accuracy: 66.1000%\n",
      "Epoch 3/20\n",
      "----------\n",
      "Training - Loss: 0.8476, Accuracy: 70.3675%\n",
      "Validation - Loss: 0.8356, Accuracy: 71.2700%\n",
      "Epoch 4/20\n",
      "----------\n",
      "Training - Loss: 0.7410, Accuracy: 74.4150%\n",
      "Validation - Loss: 0.7590, Accuracy: 73.4800%\n",
      "Epoch 5/20\n",
      "----------\n",
      "Training - Loss: 0.6724, Accuracy: 76.5575%\n",
      "Validation - Loss: 0.6496, Accuracy: 77.0400%\n",
      "Epoch 6/20\n",
      "----------\n",
      "Training - Loss: 0.6161, Accuracy: 78.7300%\n",
      "Validation - Loss: 0.8578, Accuracy: 72.2800%\n",
      "Epoch 7/20\n",
      "----------\n",
      "Training - Loss: 0.5748, Accuracy: 80.4525%\n",
      "Validation - Loss: 0.6073, Accuracy: 78.7100%\n",
      "Epoch 8/20\n",
      "----------\n",
      "Training - Loss: 0.5361, Accuracy: 81.7125%\n",
      "Validation - Loss: 0.6371, Accuracy: 77.8200%\n",
      "Epoch 9/20\n",
      "----------\n",
      "Training - Loss: 0.5089, Accuracy: 82.3975%\n",
      "Validation - Loss: 0.5436, Accuracy: 81.4300%\n",
      "Epoch 10/20\n",
      "----------\n",
      "Training - Loss: 0.4790, Accuracy: 83.7500%\n",
      "Validation - Loss: 0.5022, Accuracy: 82.9200%\n",
      "Epoch 11/20\n",
      "----------\n",
      "Training - Loss: 0.4576, Accuracy: 84.4500%\n",
      "Validation - Loss: 0.5126, Accuracy: 82.4200%\n",
      "Epoch 12/20\n",
      "----------\n",
      "Training - Loss: 0.4420, Accuracy: 84.8475%\n",
      "Validation - Loss: 0.5289, Accuracy: 81.8500%\n",
      "Epoch 13/20\n",
      "----------\n",
      "Training - Loss: 0.4172, Accuracy: 85.6525%\n",
      "Validation - Loss: 0.4707, Accuracy: 83.8200%\n",
      "Epoch 14/20\n",
      "----------\n",
      "Training - Loss: 0.4005, Accuracy: 86.1125%\n",
      "Validation - Loss: 0.5148, Accuracy: 82.4700%\n",
      "Epoch 15/20\n",
      "----------\n",
      "Training - Loss: 0.3914, Accuracy: 86.6900%\n",
      "Validation - Loss: 0.5150, Accuracy: 82.7300%\n",
      "Epoch 16/20\n",
      "----------\n",
      "Training - Loss: 0.3803, Accuracy: 87.0150%\n",
      "Validation - Loss: 0.4316, Accuracy: 85.3200%\n",
      "Epoch 17/20\n",
      "----------\n",
      "Training - Loss: 0.3695, Accuracy: 87.1925%\n",
      "Validation - Loss: 0.4451, Accuracy: 85.0200%\n",
      "Epoch 18/20\n",
      "----------\n",
      "Training - Loss: 0.3589, Accuracy: 87.7150%\n",
      "Validation - Loss: 0.4211, Accuracy: 85.6400%\n",
      "Epoch 19/20\n",
      "----------\n",
      "Training - Loss: 0.3552, Accuracy: 87.7925%\n",
      "Validation - Loss: 0.4201, Accuracy: 85.7400%\n",
      "Epoch 20/20\n",
      "----------\n",
      "Training - Loss: 0.3423, Accuracy: 88.3800%\n",
      "Validation - Loss: 0.4360, Accuracy: 84.9200%\n",
      "\n",
      " Testing hyperparameters: lr=0.021076375545009636, beta1=0.6232357930755213, beta2=0.5830985332746607, weight_decay=0.00018873257833005666\n",
      "Epoch 1/20\n",
      "----------\n",
      "Training - Loss: 1.8736, Accuracy: 30.1275%\n",
      "Validation - Loss: 1.7310, Accuracy: 35.7100%\n",
      "Epoch 2/20\n",
      "----------\n",
      "Training - Loss: 1.5665, Accuracy: 42.3825%\n",
      "Validation - Loss: 1.7635, Accuracy: 38.0600%\n",
      "Epoch 3/20\n",
      "----------\n",
      "Training - Loss: 1.4501, Accuracy: 47.1800%\n",
      "Validation - Loss: 1.6133, Accuracy: 41.4000%\n",
      "Epoch 4/20\n",
      "----------\n",
      "Training - Loss: 1.3646, Accuracy: 50.4825%\n",
      "Validation - Loss: 1.3649, Accuracy: 51.4400%\n",
      "Epoch 5/20\n",
      "----------\n",
      "Training - Loss: 1.3069, Accuracy: 52.8650%\n",
      "Validation - Loss: 1.8335, Accuracy: 41.3900%\n",
      "Epoch 6/20\n",
      "----------\n",
      "Training - Loss: 1.2804, Accuracy: 54.1750%\n",
      "Validation - Loss: 1.5263, Accuracy: 46.9000%\n",
      "Epoch 7/20\n",
      "----------\n",
      "Training - Loss: 1.2650, Accuracy: 54.9775%\n",
      "Validation - Loss: 1.7771, Accuracy: 44.4800%\n",
      "Epoch 8/20\n",
      "----------\n",
      "Training - Loss: 1.2524, Accuracy: 55.1900%\n",
      "Validation - Loss: 1.3611, Accuracy: 51.3800%\n",
      "Epoch 9/20\n",
      "----------\n",
      "Training - Loss: 1.2448, Accuracy: 55.5000%\n",
      "Validation - Loss: 1.6677, Accuracy: 44.2000%\n",
      "Epoch 10/20\n",
      "----------\n",
      "Training - Loss: 1.2352, Accuracy: 55.6650%\n",
      "Validation - Loss: 1.4642, Accuracy: 49.2100%\n",
      "Epoch 11/20\n",
      "----------\n",
      "Training - Loss: 1.2309, Accuracy: 56.0375%\n",
      "Validation - Loss: 1.9147, Accuracy: 40.0100%\n",
      "Epoch 12/20\n",
      "----------\n",
      "Training - Loss: 1.2275, Accuracy: 55.9875%\n",
      "Validation - Loss: 1.6868, Accuracy: 43.6900%\n",
      "Epoch 13/20\n",
      "----------\n",
      "Training - Loss: 1.2171, Accuracy: 56.6050%\n",
      "Validation - Loss: 1.7421, Accuracy: 43.6800%\n",
      "Epoch 14/20\n",
      "----------\n",
      "Training - Loss: 1.2148, Accuracy: 56.7450%\n",
      "Validation - Loss: 1.3570, Accuracy: 54.6100%\n",
      "Epoch 15/20\n",
      "----------\n",
      "Training - Loss: 1.2091, Accuracy: 56.6950%\n",
      "Validation - Loss: 1.5633, Accuracy: 48.5000%\n",
      "Epoch 16/20\n",
      "----------\n",
      "Training - Loss: 1.2122, Accuracy: 56.2825%\n",
      "Validation - Loss: 1.3435, Accuracy: 52.1400%\n",
      "Epoch 17/20\n",
      "----------\n",
      "Training - Loss: 1.2071, Accuracy: 56.8500%\n",
      "Validation - Loss: 1.3811, Accuracy: 51.5500%\n",
      "Epoch 18/20\n",
      "----------\n",
      "Training - Loss: 1.1984, Accuracy: 57.1225%\n",
      "Validation - Loss: 2.2089, Accuracy: 38.2000%\n",
      "Epoch 19/20\n",
      "----------\n",
      "Training - Loss: 1.2014, Accuracy: 57.2775%\n",
      "Validation - Loss: 1.4522, Accuracy: 49.2900%\n",
      "Epoch 20/20\n",
      "----------\n",
      "Training - Loss: 1.1958, Accuracy: 57.0925%\n",
      "Validation - Loss: 1.5843, Accuracy: 47.4300%\n",
      "\n",
      " Testing hyperparameters: lr=4.319620992854348e-06, beta1=0.5257667769926452, beta2=0.26751277665075723, weight_decay=0.0001624630235090775\n",
      "Epoch 1/20\n",
      "----------\n",
      "Training - Loss: 1.8845, Accuracy: 31.2800%\n",
      "Validation - Loss: 1.6789, Accuracy: 38.9300%\n",
      "Epoch 2/20\n",
      "----------\n",
      "Training - Loss: 1.6196, Accuracy: 41.1650%\n",
      "Validation - Loss: 1.5118, Accuracy: 45.2500%\n",
      "Epoch 3/20\n",
      "----------\n",
      "Training - Loss: 1.4850, Accuracy: 46.6700%\n",
      "Validation - Loss: 1.4151, Accuracy: 48.7300%\n",
      "Epoch 4/20\n",
      "----------\n",
      "Training - Loss: 1.4060, Accuracy: 49.6700%\n",
      "Validation - Loss: 1.3471, Accuracy: 50.9800%\n",
      "Epoch 5/20\n",
      "----------\n",
      "Training - Loss: 1.3402, Accuracy: 52.1375%\n",
      "Validation - Loss: 1.2911, Accuracy: 53.2300%\n",
      "Epoch 6/20\n",
      "----------\n",
      "Training - Loss: 1.2950, Accuracy: 53.6775%\n",
      "Validation - Loss: 1.2436, Accuracy: 55.4600%\n",
      "Epoch 7/20\n",
      "----------\n",
      "Training - Loss: 1.2486, Accuracy: 55.3900%\n",
      "Validation - Loss: 1.2179, Accuracy: 55.9200%\n",
      "Epoch 8/20\n",
      "----------\n",
      "Training - Loss: 1.2117, Accuracy: 56.7325%\n",
      "Validation - Loss: 1.1796, Accuracy: 57.4800%\n",
      "Epoch 9/20\n",
      "----------\n",
      "Training - Loss: 1.1823, Accuracy: 57.9125%\n",
      "Validation - Loss: 1.1489, Accuracy: 59.0600%\n",
      "Epoch 10/20\n",
      "----------\n",
      "Training - Loss: 1.1511, Accuracy: 59.4125%\n",
      "Validation - Loss: 1.1288, Accuracy: 59.5000%\n",
      "Epoch 11/20\n",
      "----------\n",
      "Training - Loss: 1.1220, Accuracy: 60.1775%\n",
      "Validation - Loss: 1.1055, Accuracy: 60.5100%\n",
      "Epoch 12/20\n",
      "----------\n",
      "Training - Loss: 1.1013, Accuracy: 61.1000%\n",
      "Validation - Loss: 1.0672, Accuracy: 61.7100%\n",
      "Epoch 13/20\n",
      "----------\n",
      "Training - Loss: 1.0761, Accuracy: 61.9200%\n",
      "Validation - Loss: 1.0644, Accuracy: 62.0000%\n",
      "Epoch 14/20\n",
      "----------\n",
      "Training - Loss: 1.0536, Accuracy: 62.5325%\n",
      "Validation - Loss: 1.0412, Accuracy: 63.1400%\n",
      "Epoch 15/20\n",
      "----------\n",
      "Training - Loss: 1.0327, Accuracy: 63.5375%\n",
      "Validation - Loss: 1.0285, Accuracy: 63.6800%\n",
      "Epoch 16/20\n",
      "----------\n",
      "Training - Loss: 1.0137, Accuracy: 64.2800%\n",
      "Validation - Loss: 1.0020, Accuracy: 64.7000%\n",
      "Epoch 17/20\n",
      "----------\n",
      "Training - Loss: 0.9940, Accuracy: 65.1350%\n",
      "Validation - Loss: 0.9858, Accuracy: 64.6300%\n",
      "Epoch 18/20\n",
      "----------\n",
      "Training - Loss: 0.9784, Accuracy: 65.6925%\n",
      "Validation - Loss: 0.9780, Accuracy: 65.0600%\n",
      "Epoch 19/20\n",
      "----------\n",
      "Training - Loss: 0.9675, Accuracy: 66.0650%\n",
      "Validation - Loss: 0.9550, Accuracy: 66.1700%\n",
      "Epoch 20/20\n",
      "----------\n",
      "Training - Loss: 0.9487, Accuracy: 66.7675%\n",
      "Validation - Loss: 0.9439, Accuracy: 67.1500%\n",
      "\n",
      " Testing hyperparameters: lr=1.992058676667113e-05, beta1=0.22156113789150145, beta2=0.3914027660060996, weight_decay=2.8120601211200726e-06\n",
      "Epoch 1/20\n",
      "----------\n",
      "Training - Loss: 1.6386, Accuracy: 39.9825%\n",
      "Validation - Loss: 1.4041, Accuracy: 48.8400%\n",
      "Epoch 2/20\n",
      "----------\n",
      "Training - Loss: 1.3334, Accuracy: 52.0400%\n",
      "Validation - Loss: 1.2292, Accuracy: 55.6700%\n",
      "Epoch 3/20\n",
      "----------\n",
      "Training - Loss: 1.1856, Accuracy: 57.9700%\n",
      "Validation - Loss: 1.0890, Accuracy: 61.4200%\n",
      "Epoch 4/20\n",
      "----------\n",
      "Training - Loss: 1.0791, Accuracy: 61.6675%\n",
      "Validation - Loss: 1.0571, Accuracy: 62.6400%\n",
      "Epoch 5/20\n",
      "----------\n",
      "Training - Loss: 0.9990, Accuracy: 64.8600%\n",
      "Validation - Loss: 0.9623, Accuracy: 65.8100%\n",
      "Epoch 6/20\n",
      "----------\n",
      "Training - Loss: 0.9408, Accuracy: 66.8050%\n",
      "Validation - Loss: 0.9199, Accuracy: 67.3600%\n",
      "Epoch 7/20\n",
      "----------\n",
      "Training - Loss: 0.8848, Accuracy: 68.9150%\n",
      "Validation - Loss: 0.8653, Accuracy: 69.5100%\n",
      "Epoch 8/20\n",
      "----------\n",
      "Training - Loss: 0.8405, Accuracy: 70.6875%\n",
      "Validation - Loss: 0.8157, Accuracy: 71.0200%\n",
      "Epoch 9/20\n",
      "----------\n",
      "Training - Loss: 0.7975, Accuracy: 72.2475%\n",
      "Validation - Loss: 0.7812, Accuracy: 72.5100%\n",
      "Epoch 10/20\n",
      "----------\n",
      "Training - Loss: 0.7547, Accuracy: 73.9775%\n",
      "Validation - Loss: 0.7831, Accuracy: 72.1500%\n",
      "Epoch 11/20\n",
      "----------\n",
      "Training - Loss: 0.7245, Accuracy: 74.5475%\n",
      "Validation - Loss: 0.7596, Accuracy: 73.0800%\n",
      "Epoch 12/20\n",
      "----------\n",
      "Training - Loss: 0.6959, Accuracy: 75.7775%\n",
      "Validation - Loss: 0.7044, Accuracy: 74.9800%\n",
      "Epoch 13/20\n",
      "----------\n",
      "Training - Loss: 0.6721, Accuracy: 76.5475%\n",
      "Validation - Loss: 0.7172, Accuracy: 74.5400%\n",
      "Epoch 14/20\n",
      "----------\n",
      "Training - Loss: 0.6392, Accuracy: 78.1325%\n",
      "Validation - Loss: 0.6750, Accuracy: 77.0200%\n",
      "Epoch 15/20\n",
      "----------\n",
      "Training - Loss: 0.6216, Accuracy: 78.3600%\n",
      "Validation - Loss: 0.6600, Accuracy: 77.0700%\n",
      "Epoch 16/20\n",
      "----------\n",
      "Training - Loss: 0.5985, Accuracy: 79.1350%\n",
      "Validation - Loss: 0.6751, Accuracy: 76.5000%\n",
      "Epoch 17/20\n",
      "----------\n",
      "Training - Loss: 0.5799, Accuracy: 79.8625%\n",
      "Validation - Loss: 0.6122, Accuracy: 78.5300%\n",
      "Epoch 18/20\n",
      "----------\n",
      "Training - Loss: 0.5646, Accuracy: 80.3650%\n",
      "Validation - Loss: 0.6265, Accuracy: 78.2500%\n",
      "Epoch 19/20\n",
      "----------\n",
      "Training - Loss: 0.5488, Accuracy: 80.9650%\n",
      "Validation - Loss: 0.6305, Accuracy: 77.6800%\n",
      "Epoch 20/20\n",
      "----------\n",
      "Training - Loss: 0.5308, Accuracy: 81.6025%\n",
      "Validation - Loss: 0.5783, Accuracy: 80.1200%\n",
      "\n",
      " Testing hyperparameters: lr=2.1573883515769794e-05, beta1=0.44745359403215, beta2=0.9114360295009349, weight_decay=2.2379478892320446e-05\n",
      "Epoch 1/20\n",
      "----------\n",
      "Training - Loss: 1.6069, Accuracy: 41.7100%\n",
      "Validation - Loss: 1.3523, Accuracy: 50.4800%\n",
      "Epoch 2/20\n",
      "----------\n",
      "Training - Loss: 1.2903, Accuracy: 53.5675%\n",
      "Validation - Loss: 1.2431, Accuracy: 54.8800%\n",
      "Epoch 3/20\n",
      "----------\n",
      "Training - Loss: 1.1447, Accuracy: 59.4150%\n",
      "Validation - Loss: 1.0729, Accuracy: 61.8800%\n",
      "Epoch 4/20\n",
      "----------\n",
      "Training - Loss: 1.0463, Accuracy: 62.9850%\n",
      "Validation - Loss: 1.0339, Accuracy: 62.9100%\n",
      "Epoch 5/20\n",
      "----------\n",
      "Training - Loss: 0.9657, Accuracy: 66.0125%\n",
      "Validation - Loss: 0.9722, Accuracy: 65.2700%\n",
      "Epoch 6/20\n",
      "----------\n",
      "Training - Loss: 0.9029, Accuracy: 68.1225%\n",
      "Validation - Loss: 0.9363, Accuracy: 66.9500%\n",
      "Epoch 7/20\n",
      "----------\n",
      "Training - Loss: 0.8501, Accuracy: 70.2200%\n",
      "Validation - Loss: 0.8188, Accuracy: 71.2300%\n",
      "Epoch 8/20\n",
      "----------\n",
      "Training - Loss: 0.8016, Accuracy: 71.7850%\n",
      "Validation - Loss: 0.8046, Accuracy: 71.7300%\n",
      "Epoch 9/20\n",
      "----------\n",
      "Training - Loss: 0.7545, Accuracy: 73.7525%\n",
      "Validation - Loss: 0.7650, Accuracy: 72.9200%\n",
      "Epoch 10/20\n",
      "----------\n",
      "Training - Loss: 0.7218, Accuracy: 75.0275%\n",
      "Validation - Loss: 0.7648, Accuracy: 72.9500%\n",
      "Epoch 11/20\n",
      "----------\n",
      "Training - Loss: 0.6851, Accuracy: 76.2825%\n",
      "Validation - Loss: 0.7043, Accuracy: 75.1500%\n",
      "Epoch 12/20\n",
      "----------\n",
      "Training - Loss: 0.6548, Accuracy: 77.3275%\n",
      "Validation - Loss: 0.6907, Accuracy: 76.3600%\n",
      "Epoch 13/20\n",
      "----------\n",
      "Training - Loss: 0.6270, Accuracy: 78.1900%\n",
      "Validation - Loss: 0.6858, Accuracy: 75.7300%\n",
      "Epoch 14/20\n",
      "----------\n",
      "Training - Loss: 0.6034, Accuracy: 79.2875%\n",
      "Validation - Loss: 0.6393, Accuracy: 77.3800%\n",
      "Epoch 15/20\n",
      "----------\n",
      "Training - Loss: 0.5763, Accuracy: 80.1350%\n",
      "Validation - Loss: 0.6246, Accuracy: 78.0900%\n",
      "Epoch 16/20\n",
      "----------\n",
      "Training - Loss: 0.5586, Accuracy: 80.8800%\n",
      "Validation - Loss: 0.6035, Accuracy: 78.8200%\n",
      "Epoch 17/20\n",
      "----------\n",
      "Training - Loss: 0.5403, Accuracy: 81.2450%\n",
      "Validation - Loss: 0.6048, Accuracy: 78.9300%\n",
      "Epoch 18/20\n",
      "----------\n",
      "Training - Loss: 0.5231, Accuracy: 81.9425%\n",
      "Validation - Loss: 0.5634, Accuracy: 80.3500%\n",
      "Epoch 19/20\n",
      "----------\n",
      "Training - Loss: 0.5078, Accuracy: 82.2950%\n",
      "Validation - Loss: 0.5851, Accuracy: 79.7200%\n",
      "Epoch 20/20\n",
      "----------\n",
      "Training - Loss: 0.4869, Accuracy: 83.2950%\n",
      "Validation - Loss: 0.5700, Accuracy: 80.4200%\n",
      "Best hyperparameters: [0.00016197546636104998, 0.9604824878987889, 0.22617535159096802, 0.0004076259041096254]\n",
      "Best validation accuracy: 86.89\n"
     ]
    }
   ],
   "source": [
    "#Second RUN with changes in data splitting and train function\n",
    "\n",
    "# Define the search space for the hyperparameters\n",
    "search_space = [Real(1e-6, 1e+0, prior='log-uniform', name='lr'),\n",
    "                Real(0.1, 0.999, name='beta1'),\n",
    "                Real(0.1, 0.999, name='beta2'),\n",
    "                Real(1e-6, 1e-3, prior='log-uniform', name='weight_decay')]\n",
    "\n",
    "n_epoch = 20\n",
    "\n",
    "# Define the objective function for the Bayesian optimization\n",
    "@use_named_args(search_space)\n",
    "def objective_ADAM(lr, beta1, beta2, weight_decay):\n",
    "\n",
    "    # Define the model\n",
    "    model = ResNet(BasicBlock, [2, 1, 1, 1])\n",
    "\n",
    "    print(f'\\n Testing hyperparameters: lr={lr}, beta1={beta1}, beta2={beta2}, weight_decay={weight_decay}')\n",
    "\n",
    "\n",
    "    # Define the optimizer with the given hyperparameters\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr, betas=(beta1, beta2), weight_decay=weight_decay)\n",
    "\n",
    "    # Train the model and return the validation accuracy\n",
    "    train_losses, train_accuracies, val_losses, val_accuracies = train_and_validate(model, optimizer, criterion, trainloader, valloader, n_epoch)\n",
    "\n",
    "\n",
    "    return -val_accuracies  # minimize negative accuracy\n",
    "\n",
    "# Perform the Bayesian optimization\n",
    "result = gp_minimize(objective_ADAM, search_space, n_calls=10, random_state=0)\n",
    "\n",
    "# Print the best hyperparameters and the corresponding validation accuracy\n",
    "print('Best hyperparameters:', result.x)\n",
    "print('Best validation accuracy:', -result.fun)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================================================================\n",
      "Layer (type:depth-idx)                   Param #\n",
      "=================================================================\n",
      "├─Conv2d: 1-1                            1,728\n",
      "├─BatchNorm2d: 1-2                       128\n",
      "├─Sequential: 1-3                        --\n",
      "|    └─BasicBlock: 2-1                   --\n",
      "|    |    └─Conv2d: 3-1                  36,864\n",
      "|    |    └─BatchNorm2d: 3-2             128\n",
      "|    |    └─Conv2d: 3-3                  36,864\n",
      "|    |    └─BatchNorm2d: 3-4             128\n",
      "|    |    └─Sequential: 3-5              --\n",
      "|    └─BasicBlock: 2-2                   --\n",
      "|    |    └─Conv2d: 3-6                  36,864\n",
      "|    |    └─BatchNorm2d: 3-7             128\n",
      "|    |    └─Conv2d: 3-8                  36,864\n",
      "|    |    └─BatchNorm2d: 3-9             128\n",
      "|    |    └─Sequential: 3-10             --\n",
      "├─Sequential: 1-4                        --\n",
      "|    └─BasicBlock: 2-3                   --\n",
      "|    |    └─Conv2d: 3-11                 73,728\n",
      "|    |    └─BatchNorm2d: 3-12            256\n",
      "|    |    └─Conv2d: 3-13                 147,456\n",
      "|    |    └─BatchNorm2d: 3-14            256\n",
      "|    |    └─Sequential: 3-15             8,448\n",
      "├─Sequential: 1-5                        --\n",
      "|    └─BasicBlock: 2-4                   --\n",
      "|    |    └─Conv2d: 3-16                 294,912\n",
      "|    |    └─BatchNorm2d: 3-17            512\n",
      "|    |    └─Conv2d: 3-18                 589,824\n",
      "|    |    └─BatchNorm2d: 3-19            512\n",
      "|    |    └─Sequential: 3-20             33,280\n",
      "├─Sequential: 1-6                        --\n",
      "|    └─BasicBlock: 2-5                   --\n",
      "|    |    └─Conv2d: 3-21                 1,179,648\n",
      "|    |    └─BatchNorm2d: 3-22            1,024\n",
      "|    |    └─Conv2d: 3-23                 2,359,296\n",
      "|    |    └─BatchNorm2d: 3-24            1,024\n",
      "|    |    └─Sequential: 3-25             132,096\n",
      "├─Linear: 1-7                            5,130\n",
      "=================================================================\n",
      "Total params: 4,977,226\n",
      "Trainable params: 4,977,226\n",
      "Non-trainable params: 0\n",
      "=================================================================\n",
      "Epoch 1/100\n",
      "----------\n",
      "Training - Loss: 1.5433, Accuracy: 43.2925%\n",
      "Validation - Loss: 1.2883, Accuracy: 53.1900%\n",
      "Epoch 2/100\n",
      "----------\n",
      "Training - Loss: 1.0952, Accuracy: 61.0600%\n",
      "Validation - Loss: 0.9698, Accuracy: 65.6200%\n",
      "Epoch 3/100\n",
      "----------\n",
      "Training - Loss: 0.9029, Accuracy: 68.0025%\n",
      "Validation - Loss: 0.8426, Accuracy: 69.8800%\n",
      "Epoch 4/100\n",
      "----------\n",
      "Training - Loss: 0.7755, Accuracy: 72.8225%\n",
      "Validation - Loss: 0.7578, Accuracy: 73.1200%\n",
      "Epoch 5/100\n",
      "----------\n",
      "Training - Loss: 0.6890, Accuracy: 76.2050%\n",
      "Validation - Loss: 0.6766, Accuracy: 76.3400%\n",
      "Epoch 6/100\n",
      "----------\n",
      "Training - Loss: 0.6301, Accuracy: 78.3100%\n",
      "Validation - Loss: 0.6574, Accuracy: 77.6200%\n",
      "Epoch 7/100\n",
      "----------\n",
      "Training - Loss: 0.5776, Accuracy: 79.9775%\n",
      "Validation - Loss: 0.6144, Accuracy: 79.0500%\n",
      "Epoch 8/100\n",
      "----------\n",
      "Training - Loss: 0.5339, Accuracy: 81.7675%\n",
      "Validation - Loss: 0.5259, Accuracy: 81.8200%\n",
      "Epoch 9/100\n",
      "----------\n",
      "Training - Loss: 0.5023, Accuracy: 82.7000%\n",
      "Validation - Loss: 0.5430, Accuracy: 81.5700%\n",
      "Epoch 10/100\n",
      "----------\n",
      "Training - Loss: 0.4745, Accuracy: 83.8000%\n",
      "Validation - Loss: 0.5069, Accuracy: 82.3700%\n",
      "Epoch 11/100\n",
      "----------\n",
      "Training - Loss: 0.4536, Accuracy: 84.3075%\n",
      "Validation - Loss: 0.4871, Accuracy: 83.4500%\n",
      "Epoch 12/100\n",
      "----------\n",
      "Training - Loss: 0.4311, Accuracy: 85.2150%\n",
      "Validation - Loss: 0.4377, Accuracy: 84.9300%\n",
      "Epoch 13/100\n",
      "----------\n",
      "Training - Loss: 0.4045, Accuracy: 86.1200%\n",
      "Validation - Loss: 0.4199, Accuracy: 85.8300%\n",
      "Epoch 14/100\n",
      "----------\n",
      "Training - Loss: 0.3939, Accuracy: 86.4200%\n",
      "Validation - Loss: 0.4280, Accuracy: 85.2600%\n",
      "Epoch 15/100\n",
      "----------\n",
      "Training - Loss: 0.3752, Accuracy: 87.3200%\n",
      "Validation - Loss: 0.4243, Accuracy: 85.2100%\n",
      "Epoch 16/100\n",
      "----------\n",
      "Training - Loss: 0.3624, Accuracy: 87.6050%\n",
      "Validation - Loss: 0.4628, Accuracy: 84.1100%\n",
      "Epoch 17/100\n",
      "----------\n",
      "Training - Loss: 0.3487, Accuracy: 88.0950%\n",
      "Validation - Loss: 0.4206, Accuracy: 85.2900%\n",
      "Epoch 18/100\n",
      "----------\n",
      "Training - Loss: 0.3416, Accuracy: 88.1950%\n",
      "Validation - Loss: 0.4105, Accuracy: 86.0500%\n",
      "Epoch 19/100\n",
      "----------\n",
      "Training - Loss: 0.3274, Accuracy: 88.8850%\n",
      "Validation - Loss: 0.3813, Accuracy: 87.1400%\n",
      "Epoch 20/100\n",
      "----------\n",
      "Training - Loss: 0.3113, Accuracy: 89.3550%\n",
      "Validation - Loss: 0.3909, Accuracy: 86.5700%\n",
      "Epoch 21/100\n",
      "----------\n",
      "Training - Loss: 0.3054, Accuracy: 89.5150%\n",
      "Validation - Loss: 0.3771, Accuracy: 87.3300%\n",
      "Epoch 22/100\n",
      "----------\n",
      "Training - Loss: 0.3041, Accuracy: 89.6000%\n",
      "Validation - Loss: 0.3684, Accuracy: 87.3900%\n",
      "Epoch 23/100\n",
      "----------\n",
      "Training - Loss: 0.2922, Accuracy: 89.9400%\n",
      "Validation - Loss: 0.3490, Accuracy: 88.1100%\n",
      "Epoch 24/100\n",
      "----------\n",
      "Training - Loss: 0.2805, Accuracy: 90.4750%\n",
      "Validation - Loss: 0.3722, Accuracy: 87.1900%\n",
      "Epoch 25/100\n",
      "----------\n",
      "Training - Loss: 0.2753, Accuracy: 90.6425%\n",
      "Validation - Loss: 0.3441, Accuracy: 88.3400%\n",
      "Epoch 26/100\n",
      "----------\n",
      "Training - Loss: 0.2733, Accuracy: 90.6825%\n",
      "Validation - Loss: 0.4047, Accuracy: 86.3200%\n",
      "Epoch 27/100\n",
      "----------\n",
      "Training - Loss: 0.2654, Accuracy: 90.9475%\n",
      "Validation - Loss: 0.3648, Accuracy: 87.7400%\n",
      "Epoch 28/100\n",
      "----------\n",
      "Training - Loss: 0.2525, Accuracy: 91.2350%\n",
      "Validation - Loss: 0.3823, Accuracy: 87.5400%\n",
      "Epoch 29/100\n",
      "----------\n",
      "Training - Loss: 0.2515, Accuracy: 91.4900%\n",
      "Validation - Loss: 0.3404, Accuracy: 88.5500%\n",
      "Epoch 30/100\n",
      "----------\n",
      "Training - Loss: 0.2459, Accuracy: 91.4625%\n",
      "Validation - Loss: 0.3388, Accuracy: 88.5100%\n",
      "Epoch 31/100\n",
      "----------\n",
      "Training - Loss: 0.2445, Accuracy: 91.4575%\n",
      "Validation - Loss: 0.3354, Accuracy: 88.7700%\n",
      "Epoch 32/100\n",
      "----------\n",
      "Training - Loss: 0.2411, Accuracy: 91.7550%\n",
      "Validation - Loss: 0.3571, Accuracy: 88.0300%\n",
      "Epoch 33/100\n",
      "----------\n",
      "Training - Loss: 0.2360, Accuracy: 91.8700%\n",
      "Validation - Loss: 0.3409, Accuracy: 88.7000%\n",
      "Epoch 34/100\n",
      "----------\n",
      "Training - Loss: 0.2329, Accuracy: 91.9225%\n",
      "Validation - Loss: 0.3338, Accuracy: 88.4400%\n",
      "Epoch 35/100\n",
      "----------\n",
      "Training - Loss: 0.2278, Accuracy: 92.1350%\n",
      "Validation - Loss: 0.3394, Accuracy: 88.5400%\n",
      "Epoch 36/100\n",
      "----------\n",
      "Training - Loss: 0.2196, Accuracy: 92.3850%\n",
      "Validation - Loss: 0.3351, Accuracy: 89.0200%\n",
      "Epoch 37/100\n",
      "----------\n",
      "Training - Loss: 0.2207, Accuracy: 92.2825%\n",
      "Validation - Loss: 0.3521, Accuracy: 88.0400%\n",
      "Epoch 38/100\n",
      "----------\n",
      "Training - Loss: 0.2189, Accuracy: 92.4425%\n",
      "Validation - Loss: 0.3181, Accuracy: 89.2900%\n",
      "Epoch 39/100\n",
      "----------\n",
      "Training - Loss: 0.2135, Accuracy: 92.7250%\n",
      "Validation - Loss: 0.3166, Accuracy: 89.3500%\n",
      "Epoch 40/100\n",
      "----------\n",
      "Training - Loss: 0.2138, Accuracy: 92.6900%\n",
      "Validation - Loss: 0.3456, Accuracy: 88.5500%\n",
      "Epoch 41/100\n",
      "----------\n",
      "Training - Loss: 0.2122, Accuracy: 92.7375%\n",
      "Validation - Loss: 0.3228, Accuracy: 89.1800%\n",
      "Epoch 42/100\n",
      "----------\n",
      "Training - Loss: 0.2041, Accuracy: 93.0975%\n",
      "Validation - Loss: 0.3330, Accuracy: 88.6400%\n",
      "Epoch 43/100\n",
      "----------\n",
      "Training - Loss: 0.2105, Accuracy: 92.7575%\n",
      "Validation - Loss: 0.3331, Accuracy: 89.2000%\n",
      "Epoch 44/100\n",
      "----------\n",
      "Training - Loss: 0.2042, Accuracy: 92.8475%\n",
      "Validation - Loss: 0.3297, Accuracy: 89.0000%\n",
      "Epoch 45/100\n",
      "----------\n",
      "Training - Loss: 0.2002, Accuracy: 93.0700%\n",
      "Validation - Loss: 0.3359, Accuracy: 88.6300%\n",
      "Epoch 46/100\n",
      "----------\n",
      "Training - Loss: 0.1975, Accuracy: 93.1625%\n",
      "Validation - Loss: 0.3064, Accuracy: 89.8800%\n",
      "Epoch 47/100\n",
      "----------\n",
      "Training - Loss: 0.1956, Accuracy: 93.3050%\n",
      "Validation - Loss: 0.3096, Accuracy: 89.6600%\n",
      "Epoch 48/100\n",
      "----------\n",
      "Training - Loss: 0.1979, Accuracy: 93.1400%\n",
      "Validation - Loss: 0.3175, Accuracy: 89.4700%\n",
      "Epoch 49/100\n",
      "----------\n",
      "Training - Loss: 0.1920, Accuracy: 93.4950%\n",
      "Validation - Loss: 0.3300, Accuracy: 89.0200%\n",
      "Epoch 50/100\n",
      "----------\n",
      "Training - Loss: 0.1934, Accuracy: 93.3600%\n",
      "Validation - Loss: 0.3157, Accuracy: 89.3400%\n",
      "Epoch 51/100\n",
      "----------\n",
      "Training - Loss: 0.1885, Accuracy: 93.5825%\n",
      "Validation - Loss: 0.3291, Accuracy: 88.8600%\n",
      "Epoch 52/100\n",
      "----------\n",
      "Training - Loss: 0.1876, Accuracy: 93.6000%\n",
      "Validation - Loss: 0.3431, Accuracy: 89.2300%\n",
      "Epoch 53/100\n",
      "----------\n",
      "Training - Loss: 0.1921, Accuracy: 93.3375%\n",
      "Validation - Loss: 0.3247, Accuracy: 89.1000%\n",
      "Epoch 54/100\n",
      "----------\n",
      "Training - Loss: 0.1850, Accuracy: 93.5850%\n",
      "Validation - Loss: 0.3099, Accuracy: 90.0000%\n",
      "Epoch 55/100\n",
      "----------\n",
      "Training - Loss: 0.1820, Accuracy: 93.8025%\n",
      "Validation - Loss: 0.3197, Accuracy: 89.2500%\n",
      "Epoch 56/100\n",
      "----------\n",
      "Training - Loss: 0.1858, Accuracy: 93.5675%\n",
      "Validation - Loss: 0.3188, Accuracy: 89.2800%\n",
      "Epoch 57/100\n",
      "----------\n",
      "Training - Loss: 0.1814, Accuracy: 93.7800%\n",
      "Validation - Loss: 0.3204, Accuracy: 89.4300%\n",
      "Epoch 58/100\n",
      "----------\n",
      "Training - Loss: 0.1864, Accuracy: 93.4850%\n",
      "Validation - Loss: 0.3399, Accuracy: 88.6000%\n",
      "Epoch 59/100\n",
      "----------\n",
      "Training - Loss: 0.1774, Accuracy: 93.8475%\n",
      "Validation - Loss: 0.3201, Accuracy: 89.3200%\n",
      "Epoch 60/100\n",
      "----------\n",
      "Training - Loss: 0.1800, Accuracy: 93.7975%\n",
      "Validation - Loss: 0.3168, Accuracy: 89.4200%\n",
      "Epoch 61/100\n",
      "----------\n",
      "Training - Loss: 0.1763, Accuracy: 93.8550%\n",
      "Validation - Loss: 0.3198, Accuracy: 89.5900%\n",
      "Epoch 62/100\n",
      "----------\n",
      "Training - Loss: 0.1765, Accuracy: 93.9050%\n",
      "Validation - Loss: 0.3124, Accuracy: 89.7000%\n",
      "Epoch 63/100\n",
      "----------\n",
      "Training - Loss: 0.1778, Accuracy: 93.6975%\n",
      "Validation - Loss: 0.3440, Accuracy: 88.9900%\n",
      "Epoch 64/100\n",
      "----------\n",
      "Training - Loss: 0.1768, Accuracy: 93.9225%\n",
      "Validation - Loss: 0.3036, Accuracy: 89.9200%\n",
      "Epoch 65/100\n",
      "----------\n",
      "Training - Loss: 0.1782, Accuracy: 93.9950%\n",
      "Validation - Loss: 0.3156, Accuracy: 89.4400%\n",
      "Epoch 66/100\n",
      "----------\n",
      "Training - Loss: 0.1763, Accuracy: 93.9700%\n",
      "Validation - Loss: 0.3102, Accuracy: 89.7700%\n",
      "Epoch 67/100\n",
      "----------\n",
      "Training - Loss: 0.1764, Accuracy: 93.9250%\n",
      "Validation - Loss: 0.3272, Accuracy: 89.5200%\n",
      "Epoch 68/100\n",
      "----------\n",
      "Training - Loss: 0.1724, Accuracy: 94.0500%\n",
      "Validation - Loss: 0.3400, Accuracy: 89.0000%\n",
      "Epoch 69/100\n",
      "----------\n",
      "Training - Loss: 0.1720, Accuracy: 94.2650%\n",
      "Validation - Loss: 0.3210, Accuracy: 89.4900%\n",
      "Epoch 70/100\n",
      "----------\n",
      "Training - Loss: 0.1723, Accuracy: 94.0000%\n",
      "Validation - Loss: 0.3106, Accuracy: 89.7300%\n",
      "Epoch 71/100\n",
      "----------\n",
      "Training - Loss: 0.1657, Accuracy: 94.3400%\n",
      "Validation - Loss: 0.3232, Accuracy: 89.6600%\n",
      "Epoch 72/100\n",
      "----------\n",
      "Training - Loss: 0.1740, Accuracy: 93.9975%\n",
      "Validation - Loss: 0.3078, Accuracy: 89.9300%\n",
      "Epoch 73/100\n",
      "----------\n",
      "Training - Loss: 0.1710, Accuracy: 94.1750%\n",
      "Validation - Loss: 0.3371, Accuracy: 88.8300%\n",
      "Epoch 74/100\n",
      "----------\n",
      "Training - Loss: 0.1684, Accuracy: 94.1775%\n",
      "Validation - Loss: 0.3380, Accuracy: 88.7300%\n",
      "Epoch 75/100\n",
      "----------\n",
      "Training - Loss: 0.1684, Accuracy: 94.1475%\n",
      "Validation - Loss: 0.3199, Accuracy: 89.4700%\n",
      "Epoch 76/100\n",
      "----------\n",
      "Training - Loss: 0.1673, Accuracy: 94.2400%\n",
      "Validation - Loss: 0.3156, Accuracy: 89.7700%\n",
      "Epoch 77/100\n",
      "----------\n",
      "Training - Loss: 0.1688, Accuracy: 94.1725%\n",
      "Validation - Loss: 0.3007, Accuracy: 90.3400%\n",
      "Epoch 78/100\n",
      "----------\n",
      "Training - Loss: 0.1697, Accuracy: 94.1900%\n",
      "Validation - Loss: 0.3315, Accuracy: 89.5000%\n",
      "Epoch 79/100\n",
      "----------\n",
      "Training - Loss: 0.1699, Accuracy: 94.1800%\n",
      "Validation - Loss: 0.3365, Accuracy: 89.1500%\n",
      "Epoch 80/100\n",
      "----------\n",
      "Training - Loss: 0.1631, Accuracy: 94.3775%\n",
      "Validation - Loss: 0.3242, Accuracy: 89.7700%\n",
      "Epoch 81/100\n",
      "----------\n",
      "Training - Loss: 0.1653, Accuracy: 94.2450%\n",
      "Validation - Loss: 0.3437, Accuracy: 89.2100%\n",
      "Epoch 82/100\n",
      "----------\n",
      "Training - Loss: 0.1635, Accuracy: 94.3625%\n",
      "Validation - Loss: 0.3346, Accuracy: 89.1000%\n",
      "Epoch 83/100\n",
      "----------\n",
      "Training - Loss: 0.1629, Accuracy: 94.3675%\n",
      "Validation - Loss: 0.3155, Accuracy: 89.6600%\n",
      "Epoch 84/100\n",
      "----------\n",
      "Training - Loss: 0.1619, Accuracy: 94.5125%\n",
      "Validation - Loss: 0.3222, Accuracy: 89.2800%\n",
      "Epoch 85/100\n",
      "----------\n",
      "Training - Loss: 0.1585, Accuracy: 94.4975%\n",
      "Validation - Loss: 0.3188, Accuracy: 89.6800%\n",
      "Epoch 86/100\n",
      "----------\n",
      "Training - Loss: 0.1643, Accuracy: 94.3400%\n",
      "Validation - Loss: 0.3125, Accuracy: 89.7300%\n",
      "Epoch 87/100\n",
      "----------\n",
      "Training - Loss: 0.1638, Accuracy: 94.4525%\n",
      "Validation - Loss: 0.3254, Accuracy: 89.4100%\n",
      "Epoch 88/100\n",
      "----------\n",
      "Training - Loss: 0.1628, Accuracy: 94.3925%\n",
      "Validation - Loss: 0.3016, Accuracy: 90.1900%\n",
      "Epoch 89/100\n",
      "----------\n",
      "Training - Loss: 0.1637, Accuracy: 94.2975%\n",
      "Validation - Loss: 0.3372, Accuracy: 89.2100%\n",
      "Epoch 90/100\n",
      "----------\n",
      "Training - Loss: 0.1580, Accuracy: 94.6675%\n",
      "Validation - Loss: 0.3079, Accuracy: 89.8000%\n",
      "Epoch 91/100\n",
      "----------\n",
      "Training - Loss: 0.1626, Accuracy: 94.3950%\n",
      "Validation - Loss: 0.3178, Accuracy: 89.6700%\n",
      "Epoch 92/100\n",
      "----------\n",
      "Training - Loss: 0.1592, Accuracy: 94.4800%\n",
      "Validation - Loss: 0.3220, Accuracy: 89.5300%\n",
      "Epoch 93/100\n",
      "----------\n",
      "Training - Loss: 0.1604, Accuracy: 94.5025%\n",
      "Validation - Loss: 0.3208, Accuracy: 89.4200%\n",
      "Epoch 94/100\n",
      "----------\n",
      "Training - Loss: 0.1600, Accuracy: 94.4475%\n",
      "Validation - Loss: 0.3284, Accuracy: 89.7500%\n",
      "Epoch 95/100\n",
      "----------\n",
      "Training - Loss: 0.1562, Accuracy: 94.7875%\n",
      "Validation - Loss: 0.3093, Accuracy: 90.0300%\n",
      "Epoch 96/100\n",
      "----------\n",
      "Training - Loss: 0.1597, Accuracy: 94.5975%\n",
      "Validation - Loss: 0.2997, Accuracy: 90.1200%\n",
      "Epoch 97/100\n",
      "----------\n",
      "Training - Loss: 0.1574, Accuracy: 94.5775%\n",
      "Validation - Loss: 0.3270, Accuracy: 89.5600%\n",
      "Epoch 98/100\n",
      "----------\n",
      "Training - Loss: 0.1575, Accuracy: 94.5375%\n",
      "Validation - Loss: 0.3179, Accuracy: 89.6300%\n",
      "Epoch 99/100\n",
      "----------\n",
      "Training - Loss: 0.1604, Accuracy: 94.5625%\n",
      "Validation - Loss: 0.3205, Accuracy: 89.8500%\n",
      "Epoch 100/100\n",
      "----------\n",
      "Training - Loss: 0.1583, Accuracy: 94.5950%\n",
      "Validation - Loss: 0.3111, Accuracy: 90.0000%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.1583023210145533, 94.595, 0.3111201276183128, 90.0)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the best hyperparameters found by Bayesian optimization\n",
    "best_lr, best_beta1, best_beta2, best_weight_decay = result.x\n",
    "\n",
    "# Define the model and dataset\n",
    "model = ResNet(BasicBlock, [2, 1, 1, 1])\n",
    "summary(model.to(device), input_size=(3, 32, 32))\n",
    "# Define the Adam optimizer with the best hyperparameters\n",
    "optimizer = optim.Adam(model.parameters(), lr=best_lr, betas=(best_beta1, best_beta2), weight_decay=best_weight_decay)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'max',patience=3)\n",
    "\n",
    "\n",
    "# Train the model with the best hyperparameters and validate\n",
    "train_and_validate(model,optimizer,criterion,trainloader,valloader,100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing - Loss: 0.3483, Accuracy: 89.7700%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.348280015411973, 89.77)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test(model,criterion,testloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perform Bayesian Optimization with SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Testing hyperparameters: lr=0.0020948412486806525, momentum=0.8589949079743348, weight_decay=0.0003748321662847933\n"
     ]
    },
    {
     "ename": "UnboundLocalError",
     "evalue": "cannot access local variable 'optimizer' where it is not associated with a value",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 26\u001b[0m\n\u001b[0;32m     23\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;241m-\u001b[39mval_accuracies  \u001b[38;5;66;03m# minimize negative accuracy\u001b[39;00m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;66;03m# Perform the Bayesian optimization\u001b[39;00m\n\u001b[1;32m---> 26\u001b[0m result \u001b[38;5;241m=\u001b[39m gp_minimize(objective_SGD, search_space, n_calls\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m     28\u001b[0m \u001b[38;5;66;03m# Print the best hyperparameters and the corresponding validation accuracy\u001b[39;00m\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBest hyperparameters:\u001b[39m\u001b[38;5;124m'\u001b[39m, result\u001b[38;5;241m.\u001b[39mx)\n",
      "File \u001b[1;32md:\\Anaconda\\Lib\\site-packages\\skopt\\optimizer\\gp.py:281\u001b[0m, in \u001b[0;36mgp_minimize\u001b[1;34m(func, dimensions, base_estimator, n_calls, n_random_starts, n_initial_points, initial_point_generator, acq_func, acq_optimizer, x0, y0, random_state, verbose, callback, n_points, n_restarts_optimizer, xi, kappa, noise, n_jobs, model_queue_size, space_constraint)\u001b[0m\n\u001b[0;32m    273\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m base_estimator \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    274\u001b[0m     base_estimator \u001b[38;5;241m=\u001b[39m cook_estimator(\n\u001b[0;32m    275\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGP\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    276\u001b[0m         space\u001b[38;5;241m=\u001b[39mspace,\n\u001b[0;32m    277\u001b[0m         random_state\u001b[38;5;241m=\u001b[39mrng\u001b[38;5;241m.\u001b[39mrandint(\u001b[38;5;241m0\u001b[39m, np\u001b[38;5;241m.\u001b[39miinfo(np\u001b[38;5;241m.\u001b[39mint32)\u001b[38;5;241m.\u001b[39mmax),\n\u001b[0;32m    278\u001b[0m         noise\u001b[38;5;241m=\u001b[39mnoise,\n\u001b[0;32m    279\u001b[0m     )\n\u001b[1;32m--> 281\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m base_minimize(\n\u001b[0;32m    282\u001b[0m     func,\n\u001b[0;32m    283\u001b[0m     space,\n\u001b[0;32m    284\u001b[0m     base_estimator\u001b[38;5;241m=\u001b[39mbase_estimator,\n\u001b[0;32m    285\u001b[0m     acq_func\u001b[38;5;241m=\u001b[39macq_func,\n\u001b[0;32m    286\u001b[0m     xi\u001b[38;5;241m=\u001b[39mxi,\n\u001b[0;32m    287\u001b[0m     kappa\u001b[38;5;241m=\u001b[39mkappa,\n\u001b[0;32m    288\u001b[0m     acq_optimizer\u001b[38;5;241m=\u001b[39macq_optimizer,\n\u001b[0;32m    289\u001b[0m     n_calls\u001b[38;5;241m=\u001b[39mn_calls,\n\u001b[0;32m    290\u001b[0m     n_points\u001b[38;5;241m=\u001b[39mn_points,\n\u001b[0;32m    291\u001b[0m     n_random_starts\u001b[38;5;241m=\u001b[39mn_random_starts,\n\u001b[0;32m    292\u001b[0m     n_initial_points\u001b[38;5;241m=\u001b[39mn_initial_points,\n\u001b[0;32m    293\u001b[0m     initial_point_generator\u001b[38;5;241m=\u001b[39minitial_point_generator,\n\u001b[0;32m    294\u001b[0m     n_restarts_optimizer\u001b[38;5;241m=\u001b[39mn_restarts_optimizer,\n\u001b[0;32m    295\u001b[0m     x0\u001b[38;5;241m=\u001b[39mx0,\n\u001b[0;32m    296\u001b[0m     y0\u001b[38;5;241m=\u001b[39my0,\n\u001b[0;32m    297\u001b[0m     random_state\u001b[38;5;241m=\u001b[39mrng,\n\u001b[0;32m    298\u001b[0m     verbose\u001b[38;5;241m=\u001b[39mverbose,\n\u001b[0;32m    299\u001b[0m     space_constraint\u001b[38;5;241m=\u001b[39mspace_constraint,\n\u001b[0;32m    300\u001b[0m     callback\u001b[38;5;241m=\u001b[39mcallback,\n\u001b[0;32m    301\u001b[0m     n_jobs\u001b[38;5;241m=\u001b[39mn_jobs,\n\u001b[0;32m    302\u001b[0m     model_queue_size\u001b[38;5;241m=\u001b[39mmodel_queue_size,\n\u001b[0;32m    303\u001b[0m )\n",
      "File \u001b[1;32md:\\Anaconda\\Lib\\site-packages\\skopt\\optimizer\\base.py:332\u001b[0m, in \u001b[0;36mbase_minimize\u001b[1;34m(func, dimensions, base_estimator, n_calls, n_random_starts, n_initial_points, initial_point_generator, acq_func, acq_optimizer, x0, y0, random_state, verbose, callback, n_points, n_restarts_optimizer, xi, kappa, n_jobs, model_queue_size, space_constraint)\u001b[0m\n\u001b[0;32m    330\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_calls):\n\u001b[0;32m    331\u001b[0m     next_x \u001b[38;5;241m=\u001b[39m optimizer\u001b[38;5;241m.\u001b[39mask()\n\u001b[1;32m--> 332\u001b[0m     next_y \u001b[38;5;241m=\u001b[39m func(next_x)\n\u001b[0;32m    333\u001b[0m     result \u001b[38;5;241m=\u001b[39m optimizer\u001b[38;5;241m.\u001b[39mtell(next_x, next_y)\n\u001b[0;32m    334\u001b[0m     result\u001b[38;5;241m.\u001b[39mspecs \u001b[38;5;241m=\u001b[39m specs\n",
      "File \u001b[1;32md:\\Anaconda\\Lib\\site-packages\\skopt\\utils.py:779\u001b[0m, in \u001b[0;36muse_named_args.<locals>.decorator.<locals>.wrapper\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m    776\u001b[0m arg_dict \u001b[38;5;241m=\u001b[39m {dim\u001b[38;5;241m.\u001b[39mname: value \u001b[38;5;28;01mfor\u001b[39;00m dim, value \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(dimensions, x)}\n\u001b[0;32m    778\u001b[0m \u001b[38;5;66;03m# Call the wrapped objective function with the named arguments.\u001b[39;00m\n\u001b[1;32m--> 779\u001b[0m objective_value \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39marg_dict)\n\u001b[0;32m    781\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m objective_value\n",
      "Cell \u001b[1;32mIn[10], line 16\u001b[0m, in \u001b[0;36mobjective_SGD\u001b[1;34m(lr, momentum, weight_decay)\u001b[0m\n\u001b[0;32m     13\u001b[0m model \u001b[38;5;241m=\u001b[39m ResNet(BasicBlock, [\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m])\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m Testing hyperparameters: lr=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlr\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, momentum=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmomentum\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, weight_decay=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mweight_decay\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 16\u001b[0m scheduler \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mlr_scheduler\u001b[38;5;241m.\u001b[39mReduceLROnPlateau(optimizer, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmax\u001b[39m\u001b[38;5;124m'\u001b[39m,patience\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m)\n\u001b[0;32m     17\u001b[0m \u001b[38;5;66;03m# Define the optimizer with the given hyperparameters\u001b[39;00m\n\u001b[0;32m     18\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m optim\u001b[38;5;241m.\u001b[39mSGD(model\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39mlr, momentum\u001b[38;5;241m=\u001b[39mmomentum, weight_decay\u001b[38;5;241m=\u001b[39mweight_decay)\n",
      "\u001b[1;31mUnboundLocalError\u001b[0m: cannot access local variable 'optimizer' where it is not associated with a value"
     ]
    }
   ],
   "source": [
    "# Define the search space for the hyperparameters\n",
    "search_space = [Real(1e-6, 0.4, prior='log-uniform', name='lr'),\n",
    "                Real(0.1, 0.999, name='momentum'),\n",
    "                Real(1e-6, 1e-3, prior='log-uniform', name='weight_decay')]\n",
    "\n",
    "n_epoch = 40\n",
    "\n",
    "# Define the objective function for the Bayesian optimization\n",
    "@use_named_args(search_space)\n",
    "def objective_SGD(lr, momentum, weight_decay):\n",
    "\n",
    "    # Define the model\n",
    "    model = ResNet(BasicBlock, [2, 1, 1, 1])\n",
    "\n",
    "    print(f'\\n Testing hyperparameters: lr={lr}, momentum={momentum}, weight_decay={weight_decay}')\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'max',patience=3)\n",
    "    # Define the optimizer with the given hyperparameters\n",
    "    optimizer = optim.SGD(model.parameters(), lr=lr, momentum=momentum, weight_decay=weight_decay)\n",
    "    # Train the model and return the validation accuracy\n",
    "    train_losses, train_accuracies, val_losses, val_accuracies = train_and_validate(model, optimizer, criterion, trainloader, valloader, n_epoch)\n",
    "\n",
    "\n",
    "    return -val_accuracies  # minimize negative accuracy\n",
    "\n",
    "# Perform the Bayesian optimization\n",
    "result = gp_minimize(objective_SGD, search_space, n_calls=10, random_state=0)\n",
    "\n",
    "# Print the best hyperparameters and the corresponding validation accuracy\n",
    "print('Best hyperparameters:', result.x)\n",
    "print('Best validation accuracy:', -result.fun)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the best hyperparameters found by Bayesian optimization\n",
    "best_lr, best_momentum, best_weight_decay = [0.0015078369731868298, 0.8516348084201026, 0.001028462547983764]\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Define the model and dataset\n",
    "model = ResNet(BasicBlock, [2, 1, 1, 1])\n",
    "# Define the SGD optimizer with the best hyperparameters\n",
    "optimizer = optim.SGD(model.parameters(), lr=best_lr, momentum=best_momentum, weight_decay=best_weight_decay)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'max')\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Train the model with the best hyperparameters and validate\n",
    "train_and_validate(model,optimizer,criterion,trainloader,valloader,100)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
